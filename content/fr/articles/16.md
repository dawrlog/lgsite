---
title: "Comment optimiser vos résultats BigQuery lorsque vous utilisez des structures de données imbriquées comme les fichiers JSON."
date: 2023-02-19
# weight: 1
# aliases: ["/first"]
tags: ["Data Warehouse", "GCP", "BigQuery"]
categories: ["Data warehouse", "Data Modeling", "Cloud"]
author: "Daniel Paes"
showToc: true
TocOpen: false
draft: false
hidemeta: false
comments: false
disableHLJS: true # to disable highlightjs
disableShare: false
disableHLJS: false
hideSummary: false
searchHidden: false
ShowReadingTime: true
ShowBreadCrumbs: true
ShowPostNavLinks: true
ShowWordCount: false
ShowRssButtonInSectionTermList: true
UseHugoToc: true
cover:
  image: "https://unsplash.com/photos/yiwEvZu7wbQ" 
---

Comme les données peuvent être utilisées pour changer la donne et vérifier la santé de votre entreprise, votre option de stockage doit refléter les besoins de votre entreprise plutôt que la commodité de la façon dont vous aviez l'habitude de gérer les choses. Avec plus de données, vous pouvez prendre de meilleures décisions ; la gestion du stockage doit être faite correctement. Sinon, vous risquez d'avoir un stockage pire que votre choix précédent parce que votre équipe était mieux préparée à le maintenir. 

Aujourd'hui, nous allons vous présenter quelques options à mettre en place lorsque vous travaillez avec BigQuery. BigQuery a gagné en popularité grâce à son interface conviviale permettant d'explorer les données de Google Analytics et Adwords. Il permet à vos utilisateurs de référencer des données froides provenant d'options de stockage d'objets telles que [Google Cloud Storage] (https://cloud.google.com/storage).

Le code présenté peut être exécuté sur la console et à partir de la ligne de commande. La section **Activer BQ depuis la ligne de commande** peut être ignorée pour ceux qui préfèrent l'interface utilisateur de la console. Extrayez les instructions SQL du code fourni dans ce tutoriel et exécutez-les depuis l'interface utilisateur de la console BigQuery à l'adresse `console.google.com`.

![](https://user-images.githubusercontent.com/78096758/220182163-cb38ef43-c2e7-495b-87f9-71aceccbae17.png)
_Accès à l'éditeur Bigquery depuis l'interface utilisateur de la console._


## Activation de BQ à partir de la ligne de commande
<br />

Si vous préférez exécuter le code présenté sur la ligne de commande, veuillez faire ce qui suit ; sinon, vous risquez de ne pas pouvoir suivre. Les commandes présentées ici peuvent être exécutées par l'interface utilisateur de la console BigQuery ou par un sous-outil de la suite gcloud appelé `bq`. 

Cet outil nous permet d'exécuter des instructions SQL à partir de la ligne de commande, en récupérant nos résultats sans utiliser l'interface utilisateur de la console. Vérifiez comment installer le client BigQuery en consultant [Installation recommandée](https://cloud.google.com/sdk/docs/install) de la suite `gcloud`. 

La configuration du projet google nécessite que votre BigQuery exécute la ligne de commande `gcloud`, comme le `bq`. This is quickly done by executing the following command from a terminal from your working machine.

```sh
gcloud config set project google-project-id
```

Une fois que vous les avez configurés, commençons par vérifier comment différencier les tâches de streaming des tâches de chargement par lots et comment cela peut aider vos coûts.
<br /><br />

## Dans la mesure du possible, préférez le chargement par lots aux insertions en continu.
<br />

Nous commençons par dire qu'il faut éviter l'ingestion de flux lorsque cela est possible et préférer l'utilisation de méthodes asynchrones. Imaginons une plateforme de commerce électronique destinée à vendre des produits et qui fournit des avis honnêtes à partir de billets de blog d'une plateforme de blogs. Les deux sont accessibles par vos clients actuels, tandis que certains des lecteurs de votre blog semblent acheter sur votre plateforme après avoir consulté vos commentaires.
<br />

En vérifiant les intérêts de leur base de clients et le nombre de ces articles de blog qui ont abouti à des ventes, on peut se concentrer sur l'extraction et la vérification des tendances de vente sur la base de ce qui commence par une simple recherche google sur l'un de vos articles de blog.
<br />

Le stockage des événements organiques à l'origine de cette piste peut apporter des informations supplémentaires qui ne le sont pas, mais les sujets agrégés des questions les plus vérifiées qui ont créé vos conversions organiques peuvent l'être.
<br />

Dans ce scénario, on peut être amené à faire l'analyse en temps réel, en traitant les données dans un état appelé `données chaudes`. Il est bon de se rappeler que l'exécution de fonctions analytiques avec des données à ce stade est généralement plus coûteuse et ne devrait être effectuée que si le retour sur investissement justifie ses besoins.
<br />

Ces données peuvent être exportées dans un stockage d'atterrissage ; ces données seront ensuite chargées dans vos tables BigQuery. En exécutant la commande ci-dessous, les données stockées sur un seau Google Cloud Storage au format JSON seront accessibles depuis votre instance BigQuery.
<br />

```sh
bq load \
--autodetect \
--source_format=NEWLINE_DELIMITED_JSON \
bigquery-target-dataset.target-table \
gs://google-cloud-storage-bucket/source-data.json 
```

Et ces données peuvent bénéficier de procédures de qualité améliorées, telles que des **politiques d'archivage**, qui déplacent automatiquement les données dans différentes classes de stockage, réduisant ainsi les coûts à la fois sur BigQuery et sur les buckets de Google Cloud Storage.
<br /><br />

## Comment assurer le contrôle des limites de vos requêtes.
<br />

Bigquery a son charme parce qu'il est convivial pour SQL, ce qui pourrait nous amener à prendre de mauvaises habitudes sans même le savoir. Vous pouvez percevoir des réductions de coûts et une amélioration des performances avec de petits changements lors de la création de vos requêtes.
<br />

Pour démontrer le fonctionnement des tables de partition, nous allons travailler avec les données publiques disponibles sur les dépôts GitHub ; vérifions leur schéma.

![](https://user-images.githubusercontent.com/78096758/220181496-eadb112f-5fff-4787-8a92-5df8f07fc6b9.png)

_Structure de tables imbriquées Bigquery_ 
<br />

Des astuces comme `limit` et les jokers pourraient ne pas donner les résultats escomptés. Et il serait préférable que vous ne récupériez que les champs souhaités de votre table et que vous utilisiez des astuces telles que la balise `maximun_bytes_billed` pour limiter les résultats en octets de la requête au lieu de votre commande bq. Vous bénéficierez également de l'avantage d'avoir tous vos résultats dans une structure aplatie au cas où vous auriez des champs imbriqués dans votre table ; consultez notre article sur [les types de données Bigquery examinés et expliqués](https://dawrlog.com/posts/10/) si vous avez besoin d'un rafraîchissement sur les types de données optimisés pour votre type de requête.
<br />

En renseignant un nombre sur un type de données `intégral`, nous indiquons également le nombre d'octets que cette requête peut consommer sans aucun format décimal. Vous ne pourrez pas exécuter la requête si la quantité de données récupérée par votre requête dépasse le seuil renseigné, et votre code **échouera** sans renvoyer de résultats si ce **seuil est atteint**.

```sh
bq query --maximum_bytes_billed=1000000 \
--use_legacy_sql=false \
'SELECT
  field1,
  field2,
  .
  .
  .
  fieldN
FROM
  `PROJECT-ID.DATASET.TABLE`;'
```
<br />

Google applique également la même configuration depuis son interface utilisateur graphique (ou UI). La page `paramètres de la requête` contient cette option ainsi que d'autres options permettant de mieux ajuster votre requête; ces options se trouvent sous `plus` dans l'interface utilisateur de la console BigQuery.

![](https://user-images.githubusercontent.com/78096758/219798792-961cb274-842f-43ad-9d04-05a534aba9ca.png)
_Filtre de l'interface utilisateur de la console BigQuery._
<br />

Le **maximum d'octets facturés** aide, mais jusqu'à une limite spécifique. Comme avec cette astuce, nous contrôlerons le total des données renvoyées. Cependant, vous pouvez obtenir de meilleurs résultats en restreignant les données sur la base des domaines qui ont un sens pour votre entreprise.
<br />

C'est ici qu'il est utile d'avoir des tables **partitionnées ou en cluster** ; commençons par comprendre comment les données sont stockées dans ces tables.
<br /><br />

## Dans ce qui consiste en des tables partitionnées et groupées.
<br />

Dans les plateformes de données événementielles, il est courant d'avoir des données éparpillées partout. BigQuery vous permet de regrouper vos données par des clés définies par vous, ce qui augmente les performances lors de l'interrogation de votre table. Les gains sont accrus si la même structure est séparée par sa création d'événements, créant ainsi une table partitionnée. Réfléchissons à une table `order` et à la manière dont ses données pourraient être stockées.
<br />

![](https://user-images.githubusercontent.com/78096758/220184794-e56b539a-7a7e-4eb8-af70-6c5a1279b903.png)
_Tables groupées par étiquettes de données (Source: [BigQuery Official doc on clustered tables](https://cloud.google.com/bigquery/docs/clustered-tables))._
<br />

Ce type de table peut augmenter les performances d'extraction tout en réduisant les coûts, car vous exécuterez vos requêtes sur un sous-ensemble de données. Bien qu'il s'agisse d'un filtre simple, les données sont stockées selon une structure optimale.
<br />

En utilisant la notation par points mentionnée précédemment, nous allons voir comment créer des tables **partitionnées et non partitionnées** à partir de structures imbriquées dans BigQuery.
<br />

## Création de tables partitionnées dans Bigquery.
<br />

Une autre bonne pratique consiste à renseigner tous les champs souhaités dans vos requêtes, en évitant autant que possible l'utilisation de caractères génériques. Ce qui peut être délicat lorsque des structures imbriquées sont utilisées, ci-dessous nous pouvons voir que la table `github_nested` pourrait ne pas l'être. Ci-dessous, nous explorons certains des champs imbriqués de la table en utilisant ce que l'on appelle la **notation des points**. En outre, une autre table peut fonctionner comme un cache. En faisant cela, le calcul nécessaire pour chaque requête sera réduit. La commande ci-dessous va créer une table non partitionnée.
<br />

```sh
bq query --maximum_bytes_billed=1000000 \
--use_legacy_sql=false \
'SELECT
  repository.organization,
  actor_attributes.company,
  actor_attributes.location,
  repository.open_issues,
  repository.watchers,
  repository.has_downloads,
  SUBSTRING(repository.pushed_at, 0, 10) as date_push
FROM
  `bigquery-public-data.samples.github_nested`;'
```
<br />

Pour vérifier chaque performance, nous allons créer une structure partitionnée en exécutant la commande ci-dessous pour créer une table partitionnée.

```sql
bq query --maximum_bytes_billed=1000000 \
--use_legacy_sql=false \
'CREATE TABLE
  `samples.github_nested_partitioned`
PARTITION BY
  date_push
CLUSTER BY location
 AS
SELECT
  repository.organization,
  actor_attributes.company,
  actor_attributes.location,
  repository.open_issues,
  repository.watchers,
  repository.has_downloads,
  cast(PARSE_DATE("%Y/%m/%d",SUBSTRING(repository.pushed_at, 0, 10)) as date) as date_push
FROM
  `bigquery-public-data.samples.github_nested`;'
```

Pour vérifier chaque performance, nous allons créer une structure partitionnée en exécutant la commande ci-dessous pour créer une table partitionnée.
<br />

Et cela peut être perçu depuis l'interface utilisateur de la console aussi. Le `github_nested` montre à quoi ressemble une table standard, alors que le `github_nested_partitioned` montre comment est une table partitionnée.

![](https://user-images.githubusercontent.com/78096758/220184872-74fa4cbd-b253-4b20-a6f9-91838435d620.png)

Maintenant, vérifions s'il y a une différence en travaillant avec elle.

<br />

## Comparaison des performances des requêtes
<br />

Pour les besoins de notre exemple, nous classons nos résultats en fonction des dépôts les plus téléchargés plutôt que des surveillants et des problèmes ouverts. Nos résultats doivent être divisés par l'entreprise, son organisation GitHub et sa localisation, comme indiqué sur sa page. La requête ci-dessous interrogera l'objet non partitionné.
<br />

```sql
bq query --maximum_bytes_billed=1000000 \
--use_legacy_sql=false \
'SELECT 
repository.organization,
actor_attributes.company,			
actor_attributes.location,			
repository.open_issues,			
repository.watchers,			
SUBSTRING(repository.pushed_at, 0, 10) as date_push,
  RANK() OVER (PARTITION BY COUNT(repository.has_downloads)
  ORDER BY 
    COUNT(repository.open_issues), COUNT(repository.watchers), COUNT(repository.has_downloads) desc) 
 FROM `YOUR_GCP_PROJECT_ID.tutorial.github_nested`
 group by 
 repository.organization,
actor_attributes.company,			
actor_attributes.location,			
repository.open_issues,			
repository.watchers,			
SUBSTRING(repository.pushed_at, 0, 10)'
```

Voyons les performances de la requête en examinant son plan de requête:

![](https://user-images.githubusercontent.com/78096758/220202269-d5343497-b572-4ea1-88ba-9456477def4a.png)
_Plan de requête d'agrégation de la table imbriquée_

Et celui du dessous interrogera celui qui est partitionné.
```sql
bq query --maximum_bytes_billed=1000000 \
--use_legacy_sql=false \
'SELECT 
organization,
company,			
location,			
open_issues,			
watchers,			
date_push,
  RANK() OVER (PARTITION BY COUNT(has_downloads)
  ORDER BY 
    COUNT(open_issues), COUNT(watchers), COUNT(has_downloads) desc) 
 FROM `YOUR_GCP_PROJECT_ID.tutorial.github_nested_partitioned`
 group by 
 organization,
company,			
location,			
open_issues,			
watchers,			
date_push'
```

Et son plan de requête :

![](https://user-images.githubusercontent.com/78096758/220202450-ecaab7ed-f49d-4551-ac74-239a512a24a8.png)
_Plan de requête d'agrégation d'une table partitionnée_
<br />

En vérifiant les détails d'exécution de chaque plan de requête, nous pouvons percevoir que la même agrégation prend moins de temps et de calcul sur la table partitionnée par rapport à une table non partitionnée.
<br />

Nous pouvons constater une amélioration même sur un petit tableau comme celui utilisé dans notre exemple, ce qui conduit à une amélioration encore plus significative sur les tableaux comportant plus de lignes. Résumons maintenant ce que nous avons vu.
<br />


## Conclusion.

Aujourd'hui, nous avons vérifié comment optimiser vos requêtes BigQuery tout en évitant les coûts inutiles en appliquant de petites modifications au code. Une solution proposée consisterait à utiliser de manière équilibrée les créneaux de calcul de vos clusters BigQuery et à éviter tout coût supplémentaire lié à l'inutilisation des capacités de calcul. 

[Réservez un rendez-vous avec nos consultants](https://calendly.com/dawrlog) pour obtenir une solution sur mesure pour votre entreprise en fonction de la nature des données que vous générez. 

À+!