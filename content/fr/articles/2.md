---
title: "Archivage des Argo Workflows dans une instance Postgres: Quoi a faire pour configurer votre entrepôt de données"
date: 2022-04-11
# weight: 1
# aliases: ["/first"]
tags: ["Kubernetes", "Argo", "Development", "Data Warehouse", "Best Practices"]
categories: ["Data Modeling", "Kubernetes"]
# series: ["Kubernetes"]
author: "Daniel Paes"
# author: ["Me", "You"] # multiple authors
showToc: true
TocOpen: false
draft: false
hidemeta: false
comments: false
# canonicalURL: "https://pipekit.io/blog/archiving-argo-workflows-postgres-database-setup"
disableHLJS: true # to disable highlightjs
disableShare: false
disableHLJS: false
hideSummary: false
searchHidden: false
ShowReadingTime: true
ShowBreadCrumbs: true
ShowPostNavLinks: true
ShowWordCount: false
ShowRssButtonInSectionTermList: true
UseHugoToc: true
cover:
    image: "https://user-images.githubusercontent.com/78096758/217074497-736145c4-11a8-4934-90ef-1d5bc3432565.png" 

---

Bonjour à tous, j'espère que vous allez bien !

Si vous connaissez [Argo Workflows](https://argoproj.github.io/workflows/), vous savez déjà qu'il peut piloter vos pipelines CI/CD, gérer vos processus ETL et orchestrer tout ensemble de tâches que vous pouvez imaginer pour un cluster Kubernetes. Mais saviez-vous qu'Argo sait aussi archiver les résultats de ses workflows dans une base de données SQL ?

Dans ce billet, je vais montrer comment Argo Workflows archive l'état des workflows dans un stockage persistant en utilisant une base de données Postgres. Pour ce faire, je présenterai un rapide résumé des composants d'Argo tout en montrant ce que signifie l'archivage de votre workflow. Nous déploierons les workflows Argo avec une base de données Postgres sur une instance locale de Kubernetes en utilisant [k3d](https://k3d.io/v5.3.0/). Enfin, nous discuterons de quelques considérations de sécurité importantes pour votre déploiement d'Argo Workflows. 

Alors, c'est parti.

## <h2>Qu'est-ce que l'option d'archivage dans les workflows Argo ?</h2> <br />

La possibilité de stocker les exécutions de flux de travail antérieures vous fournit un enregistrement précis de vos états de flux de travail antérieurs. Cet état des lieux change la donne, car il permet de provisionner vos ensembles de tâches en fonction de métriques en temps réel, comme les pics de besoins de traitement des déploiements passés. 

L'option d'archivage des flux de travail stocke vos états de flux de travail dans MySQL ou Postgres. Une fois les archives configurées, vous pouvez les utiliser pour mieux comprendre le fonctionnement de vos tâches et les points à améliorer. 

Par exemple, elles peuvent vous aider à savoir quand c'est une bonne idée de faire évoluer votre trafic à l'aide d'instances temporaires, dont les états seront également stockés dans la même base de données. Avec tous vos états conservés au fil du temps, vous pouvez appliquer des règles pour ajuster la taille de votre cluster en fonction de l'utilisation précédente ; une bonne analyse des séries chronologiques pourrait même vous faire économiser de l'argent au final.

![archivage postgres](https://user-images.githubusercontent.com/78096758/217069095-b10d7ff5-01f1-4213-98c4-02a35869a736.png)
<br />

L'archive ne stocke que les états précédents du flux de travail, et non les journaux d'instance détaillés. Les journaux d'audit détaillés sont un autre élément à prendre en compte. L'option de stockage des artefacts gère l'option de persistance des journaux détaillés, en les stockant localement par [MinIO](https://min.io/). Mais vous pouvez également configurer toute autre option de stockage d'objets. Ceci est couvert dans la [documentation officielle d'Argo](https://argoproj.github.io/argo-workflows/configure-artifact-repository/), où vous pouvez voir comment utiliser des options telles que les buckets [Google Cloud Storage](https://cloud.google.com/storage) ou [AWS S3](https://aws.amazon.com/s3/). 

Mais avant de commencer l'implémentation technique, faisons un rapide rappel sur les composants des workflows Argo. Il est nécessaire de savoir comment ils sont corrélés avec le stockage persistant de vos workflows archivés ; cette image tirée de la documentation des workflows Argo présente une vue d'ensemble de l'environnement où réside un workflow :

![Diagramme des flux de travail Argo](https://user-images.githubusercontent.com/78096758/217069401-e63ad934-46ae-4561-91ca-262089dd0131.png)
_Source : Dépôt Github du flux de travail Argo.
<br />

## <h2>How to Deploy Argo Workflows with Persistent Storage</h2><br />
Now that we know what's in store for us let's get started. We'll be using k3d to manage our local Kubernetes environment (instead of minikube and VirtualBox). In addition to k3d, you'll need to install Docker as an additional dependency. Using kubectl to interact with your Kubernetes cluster works fine, too. As for our tutorial, we'll be using local Kubernetes deployment scripts. 

First, we'll start our local control plane with the following command:

```sh
k3d cluster create cluster-demo 
```

The successful creation will provide a log similar to this one:

![Archive Info](https://user-images.githubusercontent.com/78096758/217070632-b181c8a9-f684-4cf5-a58a-9b50d79d18a6.png)
_Creating the cluster_

<br/>
Once we have our `cluster-demo`, we'll deploy our Argo Workflows instance. To install Argo Workflows, you'll need to execute the following commands:

```sh
kubectl create ns argo
kubectl apply -n argo -f https://raw.githubusercontent.com/argoproj/argo-workflows/master/manifests/quick-start-postgres.yaml 
```
La première crée un espace de nom appelé argo dans votre cluster, et la ligne suivante va déployer les composants des workflows Argo sur votre cluster, comme vous pouvez le voir ci-dessous : 

![archivage postgres](https://user-images.githubusercontent.com/78096758/217072204-32b27544-798d-489a-8e67-02994c386620.png)
_Déploiements effectués sur le cluster_

## <h2>Créer le contrôleur de workflow </h2><br />
Pour exécuter le workflow avec l'option d'archivage, vous devez d'abord changer la configuration de persistance à `archive:true` sur votre déploiement de serveur Argo. En la modifiant, vous indiquerez à votre serveur Argo de stocker les états d'exécution de votre workflow dans la base de données signalée par la clé `postgresql`. 

Nous appliquerons un nouveau `ConfigMap` dans notre espace de noms Kubernetes argo actuel avec l'instance Postgres pour stocker vos workflows archivés. Vous pouvez ensuite archiver vos workflows en utilisant l'option `archiveLogs`. 

Nous avons déployé une instance Postgres avec le YAML de démarrage rapide que nous avons utilisé précédemment. Vous en aurez besoin uniquement pour appliquer la configuration suivante à votre déploiement. Changer cette configuration permet à votre déploiement de serveur Argo d'accepter la notation `archiveLocation.archiveLogs` lors de la création de vos workflows. Nous allons commencer par créer un nouveau `workflow-controller-configmap.yml` avec le contenu suivant et le sauvegarder localement :

```sh 
apiVersion : v1
kind : ConfigMap
métadonnées :
  nom : workflow-controller-configmap
données :
  persistance : |
    connectionPool :
      maxIdleConns : 100
      maxOpenConns : 0
      connMaxLifetime : 0s
    nodeStatusOffLoad : true
    archive : true
    archiveTTL : 7d
    postgresql :
      hôte : postgres
      port : 5432
      base de données : postgres
      tableName : argo_workflows
      nom d'utilisateurSecret :
        nom : argo-postgres-config
        clé : username
      passwordSecret :
        nom : argo-postgres-config
        clé : mot de passe
  retentionPolicy : |
    terminé : 10
    échoué : 3
    erroné : 3 
```

Déployer votre environnement avec kubectl
Nous allons exposer l'interface web des workflows Argo en utilisant un équilibreur de charge sur notre espace de nom argo. L'équilibreur de charge exposera le pod exécutant le composant web aux connexions provenant de l'extérieur de Kubernetes.

```sh
kubectl apply -n argo -f workflow-controller-configmap.yml 
```
Votre serveur Argo va redémarrer avec la nouvelle configuration dans quelques minutes. N'hésitez pas à vérifier son état en exécutant `kubectl get -n argo svc,pod` sur votre cluster Kubernetes. 

```sh
kubectl get -n argo svc,pod 
```

Vous pouvez ensuite lier votre cluster Kubernetes et votre hôte au port 2746 en exécutant la commande suivante sur votre cluster :

```sh
kubectl -n argo port-forward deployment/argo-server 2746:2746 & 
```

Félicitations, vous venez de déployer les workflows Argo sur un cluster k3d. Pour confirmer que votre instance locale est opérationnelle, rendez-vous sur ``https://localhost:2746``. 

![Argo Workflow User info UI](https://user-images.githubusercontent.com/78096758/217072659-01210f43-c734-49d3-8282-0dfbc8b5c49f.png)
Page de l'interface utilisateur des flux de travail Argo.
<br />
## <h2>Testing Your Deployment</h2><br />
Félicitations pour avoir installé votre instance Argo Workflows sur votre cluster Kubernetes local avec l'option d'archivage. Et maintenant que nous avons coché cela sur notre liste, archivons nos workflows. L'ajout de l'annotation `archiveLogs` vous permet de spécifier ceux que vous souhaitez archiver, comme le montre le modèle suivant, que nous appellerons `workflow-archive.yml`.

```sh
apiVersion : argoproj.io/v1alpha1
kind : Flux de travail
métadonnées :
  generateName : archive-location-
spec :
  archiveLogs : true # active les journaux pour ce flux de travail
  point d'entrée : whalesay
  modèles :
  - nom : whalesay
    conteneur :
      image : docker/whalesay:latest
      commande : [cowsay]
      args : ["hello world"](Bonjour monde) 
```

Nous devons exécuter `argo submit -n argo --watch -f workflow-archive.yml` sur un terminal pour le déployer.

```sh 
argo submit -n argo --watch -f workflow-archive.yml 
```

En faisant cela, vous lancerez le workflow `archive-location` sous l'espace de noms `argo` ; la sortie suivante confirme que notre exemple s'est exécuté avec succès : 

![Argo Workflow Archive example](https://user-images.githubusercontent.com/78096758/217072867-ae971ca3-0776-462a-8b8b-1209498873d6.png)
_Exemple d'archivage des flux de travail Argo_<br />

Cela ne change pas sur la ligne de commande ; cependant, comme nous avons un stockage persistant pour nos workflows, vous pouvez voir leurs états précédents sur l'interface utilisateur de la console. Cela vous donnera les états précédents du workflow qui ont été exécutés avec les options d'archivage activées - et en allant sur l'interface utilisateur de la console Argo Workflows à `https://localhost:2746`, comme nous l'avons vu précédemment, vous pouvez accéder à l'option d'interface utilisateur du workflow archivé depuis les icônes de la barre de menu de gauche. Une fois que vous êtes là, vous pouvez voir toutes les exécutions passées d'un workflow. L'historique de votre workflow se trouve dans l'interface utilisateur sous "Workflows archivés" (voir ci-dessous). 

![Console des workflows archivés d'Argo](https://user-images.githubusercontent.com/78096758/217073174-b3762346-615e-4b90-8752-b2521acf769d.png)
_Ecran d'archivage des flux de travail Argo_
<br />
<br />

### <h2>Bonnes pratiques de sécurité pour l'archivage des flux de travail Argo dans Postgres.</h2><br />
Dans notre travail, nous avons déployé une instance Argo avec l'option d'archivage configurée avec une base de données Postgres. Comme mentionné précédemment, ce code n'est pas prêt pour la production. Comme prochaine étape, je suggère de gérer vos jetons d'accès pour sécuriser votre instance Argo. 

Une bonne pratique est d'éviter les valeurs codées en dur pour les informations d'exécution du serveur lorsque cela est possible. Votre infrastructure devrait générer des données comme votre nom d'hôte Postgres au moment de l'exécution au lieu de les coder en dur. Votre infrastructure devrait utiliser des secrets pour stocker des informations sensibles comme les clés d'accès au référentiel.

![Archivage Postgres](https://user-images.githubusercontent.com/78096758/217073499-91ffe20f-6625-42ff-9688-b1b436fa6f1f.png)
_Archivage Postgres_

Jetez un œil à cette [introduction sur les secrets et les configmaps dans Kubernetes](https://opensource.com/article/19/6/introduction-kubernetes-secrets-and-configmaps), pour plus de détails sur les informations Kubernetes qui doivent être discrètes. L'adoption de bonnes pratiques de sécurité comme celle-ci dès le début est plus facile pour vos utilisateurs et vos développeurs lorsque vous commencez à évoluer. En outre, l'automatisation de la configuration permet de réduire la [surface d'attaque](https://csrc.nist.gov/glossary/term/attack_surface) de votre environnement tout en réduisant les tâches de gestion de l'infrastructure. 

Voici un [article de blog utile](https://blog.argoproj.io/practical-argo-workflows-hardening-dd8429acc1ce) contenant d'autres bonnes pratiques de sécurité Argo par le responsable des flux de travail Argo, Alex Collins.

## <h2>Conclusion</h2><br />
Nous avons déployé Argo Workflows localement et archivé un workflow en utilisant une base de données Postgres dans ce post. Les scripts présentés ici sont de bons points de départ pour comprendre et expérimenter l'option d'archivage d'Argo Workflows, mais gardez à l'esprit que certains facteurs critiques sont manquants pour un environnement entièrement cloud native. 

A+ !