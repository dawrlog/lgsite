---
title: "Comment bien evaluer vos Value Stream pour votre pratique DataOps?"
date: 2021-11-24
# weight: 1
# aliases: ["/first"]
tags: ["DataOps", "Lean Agile", "Best Practices"]
categories: ["DataOps", "Lean Agile", "Best Practices"]
# series: ["Best Practices"]
author: "Daniel Paes"
# author: ["Me", "You"] # multiple authors
showToc: true
TocOpen: false
draft: false
hidemeta: false
comments: false
# canonicalURL: "https://www.enov8.com/blog/how-to-value-stream-dataops-2/"
disableHLJS: true # to disable highlightjs
disableShare: false
disableHLJS: false
hideSummary: false
searchHidden: false
ShowReadingTime: true
ShowBreadCrumbs: true
ShowPostNavLinks: true
ShowWordCount: false
ShowRssButtonInSectionTermList: true
UseHugoToc: true
cover:
    image: "https://user-images.githubusercontent.com/78096758/217092056-02f22c71-de93-4223-88c0-fc60f8f662b1.png" 
---

Bonjour à tous, aujourd'hui nous allons vérifier comment valoriser correctement votre initiative DataOps.

Les améliorations apportées à l'ingestion des données ont rendu évidente la quantité de données perdues lors de la génération d'insights. Cependant, en l'absence de méthodologies telles que [The DataOps Manifesto](https://www.dataopsmanifesto.org/), certaines entreprises s'efforcent encore de combiner les pipelines de données des anciennes bases de données, telles qu'une base de données ADABAS, avec les nouvelles bases de données, telles que MongoDB ou Neo4j. 

Et il est toujours bon de rappeler que ces anciens systèmes ne sont pas faciles à abandonner. La plupart d'entre eux sont responsables du traitement de base (comme les transactions bancaires en Cobol, par exemple). En tant que tels, il n'est pas intéressant de les changer, car c'est trop problématique. 

Cela dit, je pense que l'intégration des nouvelles applications et des bases de données existantes est l'un des [plus grands défis](https://www.docshifter.com/blog/what-to-do-with-legacy-data/) pour les entreprises axées sur les données. Cependant, les méthodologies et les cadres d'ingestion de données ont connu des avancées significatives au cours des dernières années.
<br /><br />

## <h2>Pourquoi est-il si essentiel de disposer de données précises ? </h2><br />
Avec des pipelines d'ingestion de données optimisés, vous pouvez améliorer votre prise de décision. Dans le même temps, la mise à jour de vos anciens systèmes centrés sur le sujet en applications modulaires semble prometteuse, non ? 

La bonne nouvelle, c'est qu'il ne s'agit pas d'un rêve irréalisable ! Grâce aux progrès de la puissance informatique, il est désormais possible de faire beaucoup plus avec très peu. Nous pouvons maintenant déconstruire les applications gonflées en versions plus fines. 

En utilisant des concepts qui n'étaient possibles qu'en théorie, nous pouvons maintenant ingérer des données provenant d'endroits inhabituels. Par exemple, nous pouvons avoir un pipeline automatisé pour ingérer des données à partir de documents numérisés grâce à la [reconnaissance optique de caractères](https://en.wikipedia.org/wiki/Optical_character_recognition), ou OCR. C'est génial, non ? 

Dans ce billet, je veux vous aider à comprendre comment votre organisation pourra bénéficier d'un environnement DataOps mature. Tout d'abord, je présenterai ce qu'est DataOps et pourquoi il ne s'agit pas seulement de DevOps pour les données. Ensuite, j'expliquerai certains avantages importants qui découlent de la cartographie des flux de valeur pour votre propre pratique DataOps. Enfin, je présenterai quelques considérations relatives à l'application du cadre DataOps à votre équipe.
<br /><br /> 

## <h2>Qu'est-ce que DataOps ? </h2><br />
Il est difficile de fournir à vos utilisateurs les mesures les plus précises pour les tableaux de bord existants avec plusieurs fournisseurs de données. La situation s'aggrave lorsque votre base de données est si lourdement grevée de dettes techniques que la réalisation d'une tâche aussi simple que la création d'un [indicateur clé de processus](https://kpi.org/KPI-Basics), ou KPI, est un véritable cauchemar. 

Et c'est là que DataOps vient à la rescousse ! Il permet à vos utilisateurs de consommer vos données plus rapidement et dans un environnement automatisé intégré à la version la plus récente de vos fournisseurs de données. Pas mal, non ? 

J'aime à rappeler que ce n'est pas quelque chose de nouveau, car le [système d'aide à la décision](https://www.investopedia.com/terms/d/decision-support-system.asp) (SAD) consiste en un environnement automatisé pour vos pipelines analytiques. Et je crois que les DSS ont toujours joué un rôle essentiel dans toute entreprise. Les avantages pour les parties prenantes comprennent une compréhension complète du processus de votre chaîne d'approvisionnement ou la possibilité de savoir plus rapidement quel département ou produit est le plus rentable, pour n'en citer que quelques-uns. 

Les fournisseurs de données chargent ces systèmes, qui peuvent être n'importe quelle source d'information pour vos besoins. Voici quelques exemples d'informations fournies par les fournisseurs de données 

- Données sur les ressources humaines
- Données de campagnes d'agences
- Dispositifs IoT de la chaîne d'approvisionnement
- Systèmes de facturation
- Journaux de serveur et de trafic
<br /><br /> 

## <h2>DataOps vs systèmes d'aide à la décision. </h2><br />
Vous voyez souvent des pipelines de données orchestrés provenant de différents fournisseurs de données dans les systèmes de gestion des données existants. Ainsi, chaque fournisseur de données charge ses données dans cette base de données centralisée. Mais ces flux de données indépendants entraînent des données incohérentes, ce qui rend difficile la confiance dans les résultats présentés par le DSS. 

Ce que DataOps facilite, c'est **de meilleurs résultats avec un DSS optimisé** ! Grâce à l'approche agile, DataOps renforce une approche plus centrée sur le client par rapport au DSS en raison de son architecture modulaire. En outre, DataOps allège les contraintes d'évolutivité, d'automatisation et de sécurité grâce à la réutilisation de composants utilisés par d'autres pipelines de données. 

Ces composants peuvent aller d'une simple connectivité de base de données à une règle de gestion utilisée par le département des finances et dont les ressources humaines pourraient bénéficier. Tout cela grâce à des référentiels centralisés, standardisés et réutilisables.
<br /><br /> 

## <h2>Les points d'intersection et de divergence entre DataOps et DevOps</h2><br />
Alors que DataOps ressemble à DevOps pour les données, j'aime à rappeler que les objectifs de DevOps et DataOps sont différents, bien que les méthodologies partagent les mêmes principes. 

DevOps se concentre sur l'assouplissement du développement pour inclure les opérations. En revanche, l'objectif de DataOps est de rendre le développement analytique plus fonctionnel. DataOps utilise le [contrôle statistique des processus](https://en.wikipedia.org/wiki/Statistical_process_control), l'approche mathématique utilisée dans la [production allégée](https://en.wikipedia.org/wiki/Lean_manufacturing), les disciplines DevOps et les meilleures pratiques du [Manifeste Agile](https://en.wikipedia.org/wiki/Agile_software_development#The_Manifesto_for_Agile_Software_Development). 

Avec ces stratégies en place, vous pouvez découpler votre environnement ; DataOps facilite le détachement de votre logique métier et des contraintes techniques de vos pipelines de données. Ainsi, vous êtes plus confiant dans vos données tout en permettant à vos équipes de mieux réagir aux tendances des données. 

Vous bénéficierez de l'efficacité et des résultats plus rapidement lors de la conception des composants de votre pipeline de données. Et vos équipes se concentreront davantage sur la création de valeur plutôt que d'être liées par des décisions techniques prises dans le passé. 

Par ailleurs, j'aime toujours évoquer les gains de sécurité résultant d'un déploiement correct des DataOps : des systèmes robustes et sécurisés, moins sujets aux violations et aux fuites !
<br /><br /> 

## <h2>Avantages à considérer lors de la cartographie de vos flux de valeur</h2><br />
Maintenant que nous savons ce qu'est DataOps, je veux présenter les avantages d'une cartographie correcte de vos [flux de valeurs](https://www.atlassian.com/continuous-delivery/principles/value-stream-mapping). 

Je me concentre ici sur les avantages pour vos pipelines de données, bien qu'ils puissent également s'appliquer à vos déploiements d'applications. Du point de vue de l'entreprise, la principale valeur ajoutée par l'adoption de DataOps est la possibilité d'explorer rapidement de nouvelles sources de données. 

Voici les avantages de la [valeur ajoutée](https://berteig.com/how-to-apply-agile/value-added-work-basic-lean-concepts/) pour le client lors de la cartographie de vos flux de valeur.
<br /><br /> 

## <h3>Un meilleur contrôle grâce au découplage technique.</h3><br />
Comme je l'ai déjà mentionné, les fournisseurs de données sont toutes les applications sources contenant des données pertinentes pour votre analyse. En d'autres termes, ce sont les points d'entrée des données qui alimentent votre pipeline de données. 

Ces applications produisent des données à l'état brut. Et comme leur nom l'indique, ces données doivent être laissées aussi intactes que possible. C'est utile en cas de retraitement ou d'analyse de la lignée des données. 

Ces données nécessitent des étapes de traitement supplémentaires afin de les débarrasser des bruits inutiles, car leur forme originale peut ne pas correspondre à vos besoins. Cependant, à partir de cette sortie, vous pouvez extraire les métriques nécessaires pour couvrir les besoins de vos utilisateurs. 

Je souhaite également évoquer l'une des valeurs du découplage conscient : son contrôle automatisé robuste du pipeline de données de chaque composant. Cette orchestration apporte des mesures de qualité supplémentaires, permettant d'augmenter la productivité puisque vos utilisateurs n'auront pas à effectuer des tâches répétitives.
<br /><br /> 

## <h3>Exploration rapide des fournisseurs de données existants et nouveaux.</h3><br />
Sur les systèmes patrimoniaux, le développement de nouveaux pipelines est chaotique, comme mentionné précédemment. L'approche DataOps permet également une exploration rapide de vos fournisseurs de données. 

DataOps facilite la création de composants conformes grâce à son déploiement modulaire. Ce que je veux dire par là, c'est que vous pouvez réutiliser des composants déjà déployés et testés. 

En d'autres termes, DataOps permet un état d'esprit d'amélioration continue. Par conséquent, il réduira considérablement vos coûts de développement et augmentera en même temps votre retour sur investissement. 

Votre équipe s'occupera de tâches plus difficiles pour apporter de la valeur à l'entreprise, et non plus des activités quotidiennes de traitement des données. En conséquence, vous bénéficiez d'un gain de productivité instantané grâce au déploiement automatisé de votre application.
<br /><br /> 

## <h3>Gouvernance fiable des données.</h3><br />
Grâce aux pipelines de données automatisés déployés par DataOps, il devient plus facile de retracer comment vos utilisateurs consomment vos données. Ces informations peuvent vous aider à répondre rapidement à des questions récurrentes. 

Vos utilisateurs peuvent voir où se trouve la logique métier en un clin d'œil. De plus, la référence entre son nom canonique et son nom d'implémentation technique devient facile à assimiler puisque les nouveaux analystes qui se joignent à vos projets en font une source attrayante pour le profilage de vos données. 

Par conséquent, un solide datalog de vos fournisseurs de données est une étape obligatoire à laquelle il faut penser lors de la cartographie de vos flux de valeur, à mon avis. Il devient facile de gérer vos pipelines de données lorsque vous créez un catalogue métier conforme au niveau de l'entreprise. Toutes ces informations structurées sur vos fournisseurs de données créent un catalogue de données intuitif. 

Ces informations, également appelées métadonnées, fournissent le contexte commercial dans lequel ces données donnent leur valeur. En d'autres termes, vos informations deviennent plus précises.
<br /><br /> 

## <h2>Considérations importantes concernant votre propre déploiement de DataOps.</h2><br />
Ce que nous avons vu jusqu'à présent montre comment des modules détachés conformes permettent de créer un catalogue de données plus robuste pour votre entreprise. En outre, la cohérence entre vos composants analytiques permet de clarifier les points sur lesquels vous pouvez améliorer votre ingestion de données. 

J'aime toujours rappeler que ces améliorations ne sont pas gratuites. Comme vous réagirez plus rapidement et plus judicieusement, soyez prêt à remodeler certains des processus internes de votre entreprise. N'oubliez pas qu'il est difficile d'apprendre de nouveaux tours à un vieux chien. Attendez-vous donc à une certaine résistance de la part de vos coéquipiers plus expérimentés. 

Un pipeline de données auto-réparateur évolue horizontalement ou verticalement selon les besoins. Ainsi, vous pouvez ajouter des unités supplémentaires pour la puissance de traitement (ce que l'on appelle la mise à l'échelle horizontale) ou améliorer vos clusters (ce que l'on appelle la mise à l'échelle verticale) lorsque vos ensembles commencent à avoir des problèmes de goulot d'étranglement lors du traitement de vos données ; **_Remember the rule of thumb_** : 

> Il est plus facile d'enrichir vos sorties lorsque vous êtes pleinement conscient de l'étendue de vos données. Ainsi, en plus de ses composants modulaires, DataOps permet d'effectuer des actions telles que le masquage et l'obscurcissement de vos données de manière plus fluide dans les premières étapes de leur traitement. 

Avec DataOps, vous construisez un **pipe de données fiable** capable de réagir aux nouveaux concepts et technologies à la **_même vitesse_** que l'évolution de votre **_entreprise_**.
<br /><br /> 

## <h2>Réflexions finales.</h2><br />
Dans ce billet, j'ai donné un aperçu de ce que vous gagnerez en déployant correctement DataOps. Le résultat est un mélange de valeur ajoutée commerciale et technique, car vous disposerez de pipelines de données orchestrés minces et robustes.  

J'ai commencé par présenter ce qu'est DataOps et la valeur commerciale qu'elle apporte. Ensuite, j'ai expliqué où elle se recoupe et où ses objectifs diffèrent des méthodologies agiles et DevOps. 

Nous avons également jeté un rapide coup d'œil à ce que je crois être les avantages à court terme du déploiement correct d'une mise en œuvre DataOps mature et comment les déploiements automatisés peuvent ajouter de la valeur technique. 

Enfin, nous avons vu certains défis que votre équipe peut rencontrer lorsque vous adoptez DataOps. Par exemple, votre unité peut être **résistante** à **_adopter de nouvelles technologies et méthodologies_**. Cependant, nous avons également vu les avantages d'un déploiement correct en tant que **_catalogue de données concis_**. 

Rappelez-vous simplement que vous devez mettre en œuvre l'intégralité des exigences de DataOps. Ne vous attendez donc pas à une mise en œuvre fiable de DataOps avec des déploiements partiels des disciplines agiles ou DevOps. 

Si vous avez besoin d'aide pour transformer vos données, vous pouvez [nous contacter](https://calendly.com/dawrlog) pour toute question et même découvrir de nouvelles informations dont vous n'étiez pas conscient grâce à une meilleure compréhension de vos données.

À+!