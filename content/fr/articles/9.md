---
title: "Files d'attente de requêtes SQL sur Redshift : Le guide complet"
date: 2021-11-19
# weight: 1
# aliases: ["/first"]
tags: ["Data Warehouse", "Best Practices", "AWS", "Redshift"]
categories: ["Data Modeling"]
# series: ["Data Stack"]
author: "Daniel Paes"
# author: ["Me", "You"] # multiple authors
showToc: true
TocOpen: false
draft: false
hidemeta: false
comments: false
# canonicalURL: "https://blog.panoply.io/the-redshift-query-queues-challenges-and-some-tips"
disableHLJS: true # to disable highlightjs
disableShare: false
disableHLJS: false
hideSummary: false
searchHidden: false
ShowReadingTime: true
ShowBreadCrumbs: true
ShowPostNavLinks: true
ShowWordCount: false
ShowRssButtonInSectionTermList: true
UseHugoToc: true
cover:
    image: "https://user-images.githubusercontent.com/78096758/217089342-26bc2683-98d9-4b10-b2b1-273d2a34ba9b.png" 
---

Salut tout le monde, j'espère que tout va bien. 

Même la base de données la plus puissante est toujours sujette à l'erreur terrifiante que tout système de base de données peut rencontrer : **_les goulots d'étranglement des requêtes_**.

Parfois, les systèmes qui gèrent nos requêtes ne peuvent pas traiter de la même manière que nous. Ainsi, nos questions renvoient des résultats précis grâce à une puissance de traitement supplémentaire.

Dans cet article, je vais présenter le fonctionnement des files d'attente de requêtes Redshift. Nous couvrirons également le fonctionnement de la concurrence à un haut niveau sur Redshift.

Ces informations nous seront utiles lorsque nous descendrons plus loin dans le terrier et que nous superviserons le déploiement d'un bon ami, bien que parfois menaçant, la **gestion de la charge de travail (ou WLM)** sur Redshift.

Nous terminerons par une conclusion rapide de ce que nous avons vu et par quelques techniques d'optimisation des requêtes.

Les optimisations de requêtes sont très pratiques car elles aident à nettoyer le mauvais code. Puis d'augmenter la vitesse de vos transformations, ce qui permet d'explorer plus de données avec moins. En bref, la bonne vieille [frugalité des données](https://hellofuture.orange.com/en/towards-a-less-data-and-energy-intensive-ai/).

## <h2>Qu'est-ce que Redshift, et comment fonctionne le traitement des requêtes?</h2><br />

Redshift est la version d'Amazon d'un système de base de données à traitement massivement parallèle (ou MPP).

Ce type de base de données est le premier choix pour le stockage d'entrepôts de données grâce à ses capacités de traitement de quantités massives de données en parallèle. Quant aux deux autres grands fournisseurs de services en nuage, il y a [BigQuery](https://cloud.google.com/bigquery) sur Google Cloud Platform et [Synapse Analytics](https://azure.microsoft.com/en-ca/services/synapse-analytics/) sur Microsoft Azure.

Examinons maintenant plus en détail le processus d'interrogation.

Traitement des requêtes
Une fois que la requête est lancée (soit par la **console**, soit par un accès pragmatique - les commandes **API** et **CLI** suivent la même procédure), elle génère un **plan de requête**, qui est la traduction de la requête effectuée par l'analyseur syntaxique pendant l'extraction des données des nœuds.

Avec ce plan d'exécution, nous pouvons commencer à inspecter les goulots d'étranglement de votre code.

Voici un exemple d'une commande **EXPLAIN** Redshift :

```sql
explain

select lastname, catname, venuename, venuecity, venuestate, eventname,
month, sum(pricepaid) as buyercost, max(totalprice) as maxtotalprice
from category join event on category.catid = event.catid
join venue on venue.venueid = event.venueid
join sales on sales.eventid = event.eventid
join listing on sales.listid = listing.listid
join date on sales.dateid = date.dateid
join users on users.userid = sales.buyerid
group by lastname, catname, venuename, venuecity, venuestate, eventname, month
having sum(pricepaid)>9999
order by catname, buyercost desc;
```
A partir des résultats **EXPLAIN** ci-dessus, je veux identifier les tables : **_category, venue, sales, listing, date, et users_**. Chacune d'entre elles utilise la clause **INNER JOIN**.

La puissance de Redshift repose sur un traitement lourd, donc plus ces tables sont grandes, mieux c'est pour vous, sur le plan informatique.

Mais comment pouvez-vous le savoir ? Plus profondément, comment pouvez-vous identifier les plus petites tables pour que vous puissiez prendre les métriques et les mesures nécessaires si importantes pour vos KPI ?

C'est ici que le **plan de requête** est utile ; ci-dessous, vous pouvez voir toutes les étapes que Redshift exécute en fonction du SQL que vous avez écrit. C'est donc ici que Redshift vous dit si ce que vous avez écrit est ce que Redshift a compris.

Voici le résultat de la commande **EXPLAIN** ci-dessus :

![queryplan](https://user-images.githubusercontent.com/78096758/217089951-c6cedc17-23d3-4a99-b1f3-bae48235d2ba.png)
Résultats du plan de requête._

Maintenant que nous savons comment créer le plan de requête, nous pouvons approfondir l'optimisation des requêtes, qui n'est rien d'autre que le remaniement de vos requêtes pour réduire les coûts de traitement décrits par les étapes du plan de requête.

<br /><br />

## <h2>Qu'est-ce que la gestion de la charge de travail, ou WLM ?</h2><br />
L'un des moyens les plus rapides de gérer vos flux de requêtes est la gestion de la charge de travail. Avec cette fonction, vous ne sacrifiez pas votre capacité à répondre à des questions rapides en raison de processus longs, car elle permet une certaine flexibilité dans la gestion de vos charges de travail.

Imaginons le scénario suivant :

- Votre data scientist principal déploie certains modèles d'apprentissage automatique pour détecter d'éventuelles activités frauduleuses.
- Ces activités doivent être croisées avec l'emplacement géographique des dernières transactions.
- Ensuite, ces microservices indépendants chaotiques commencent à s'exécuter sur vos clusters Redshift au moment précis où vos indicateurs de performance clés déclenchent de nouveaux processus sur le même cluster Redshift.

C'est drôle, non ?

WLM vient à la rescousse, car il crée ce que l'on appelle des **queues de requêtes** au moment de l'exécution. WLM regroupe ces files d'attente par un label de groupe de requêtes défini par l'utilisateur avant l'exécution de la requête.

Ces files d'attente ont des niveaux de concurrence, c'est-à-dire le nombre de charges de travail lancées en même temps.
<br /><br />

## <h2>Pour nous habituer à Workload Manager, ou WLM</h2><br />
WLM est proposé avec deux types d'implémentations : [automatique](https://docs.aws.amazon.com/redshift/latest/dg/automatic-wlm.html), où Redshift se charge de gérer la mémoire de vos requêtes et l'allocation de la concurrence, et [manuel](https://docs.aws.amazon.com/redshift/latest/dg/cm-c-defining-query-queues.html), où vous fournissez ces valeurs à la place.

Ci-dessous, je souhaite partager les **_tableaux et vues système_** utiles qui devraient être utilisés comme points de départ lorsque vous avez besoin d'améliorer, ou simplement de vérifier, vos charges de travail WLM.

- [STL_WLM_ERROR](https://docs.aws.amazon.com/redshift/latest/dg/r_STL_WLM_ERROR.html)
- [STL_WLM_QUERY](https://docs.aws.amazon.com/redshift/latest/dg/r_STL_WLM_QUERY.html)
- [STV_WLM_CLASSIFICATION_CONFIG](https://docs.aws.amazon.com/redshift/latest/dg/r_STV_WLM_CLASSIFICATION_CONFIG.html)
- [STV_WLM_QUERY_QUEUE_STATE](https://docs.aws.amazon.com/redshift/latest/dg/r_STV_WLM_QUERY_QUEUE_STATE.html)
- [STV_WLM_QUERY_STATE](https://docs.aws.amazon.com/redshift/latest/dg/r_STV_WLM_QUERY_STATE.html)
- [STV_WLM_QUERY_TASK_STATE](https://docs.aws.amazon.com/redshift/latest/dg/r_STV_WLM_QUERY_TASK_STATE.html)
- [STV_WLM_SERVICE_CLASS_CONFIG](https://docs.aws.amazon.com/redshift/latest/dg/r_STV_WLM_SERVICE_CLASS_CONFIG.html)
- [STV_WLM_SERVICE_CLASS_STATE](https://docs.aws.amazon.com/redshift/latest/dg/r_STV_WLM_SERVICE_CLASS_STATE.html)

<br /><br />

## <h2>Les choses à faire et à ne pas faire en matière d'échelonnement de la concurrence.</h2><br />
Une fois que vous avez activé votre WLM, vous activez une fonction pratique utilisée sur le traitement massif : **mise à l'échelle concomitante** ! Vous percevrez les gains du processus d'écriture dans la cible pour la cohérence sur un débit plus élevé avec des demandes de sessions multiples.

Toujours est-il que lorsque la fonctionnalité est active, la mise à l'échelle concurrentielle est appliquée pour les opérations **_read_** et **_write_**. Il prend également en charge les instructions SQL Data Manipulation Language, les bons vieux **INSERT**, **DELETE** et **UPDATE**. Il prend également en charge l'instruction **CREATE** et [Redshift COPY](https://docs.aws.amazon.com/redshift/latest/dg/r_COPY.html), ce qui vous permet de couvrir la plupart de vos **charges de données quotidiennes**.

Les limitations les plus critiques de la mise à l'échelle de la concurrence sont la limitation de ANALYZE pour les commandes COPY et l'impossibilité d'utiliser COPY à partir de Redshift Spectrum ou lorsque vous interrogez des données à partir de votre stockage HDFS dans vos clusters EMR. Étant donné que la commande COPY est l'option suggérée pour importer des données massives dans des tables Redshift natives, ne pas l'exécuter en parallèle peut limiter l'utilisation de la commande COPY pour votre cas d'utilisation.

Il est également important de se rappeler que vous devez confirmer si la région où se trouve votre cluster Redshift dispose de la fonction de mise à l'échelle de la concurrence ; pour une référence rapide, regardez ici.

Changez l'option **Concurrency Scaling Mode** en **auto** sur votre file d'attente WLM, et ce faisant, vous activerez le routage de vos requêtes dans les clusters de mise à l'échelle de la concurrence.
<br /><br />

## <h2>Obtenir des statistiques pour votre WLM</h2><br />
Avec votre WLM activé et vos files d'attente avec le "Concurrency Scaling Mode" activé sur auto, vous pouvez suivre ce qui se passe dans votre cluster.

Pour ce faire, vous pouvez aller dans l'éditeur de requêtes de votre choix ou dans la console Redshift et exécuter la requête suivante :
<br /><br />

***Requête SQL pour le suivi des files d'attente concurrentes***

``` sh 
SELECT w.service_class AS queue
, q.concurrency_scaling_status
, COUNT( * ) AS queries
, SUM( q.aborted ) AS aborted
, SUM( ROUND( total_queue_time::NUMERIC / 1000000,2 ) ) AS queue_secs
, SUM( ROUND( total_exec_time::NUMERIC / 1000000,2 ) ) AS exec_secs
FROM stl_query q
JOIN stl_wlm_query w
USING (userid,query)
WHERE q.userid > 1
AND q.starttime > # Time on format: 'YYYY-MM-DD 24HH:MI:SS'
AND q.endtime < # Time on format: 'YYYY-MM-DD 24HH:MI:SS'
GROUP BY 1,2
ORDER BY 1,2;
```

Les résultats de la requête vous fourniront un spectre complet de ce qui se passe sur votre cluster, en accordant toutes les informations nécessaires du point de vue de la gestion du cluster Redshift. Toutes ces informations sont utiles lorsque vous cherchez à savoir quelles sessions sont actives ou non sur vos ensembles (vous pouvez vérifier à quoi ressemblerait le résultat ci-dessous).

![concurrent](https://user-images.githubusercontent.com/78096758/217090175-daebfb60-fb6e-4a39-83f8-838eae68fb11.png)
_Résultats des requêtes_

En plus des mesures collectées par [AWS CloudWatch](https://aws.amazon.com/cloudwatch/) et [AWS CloudTrail](https://aws.amazon.com/cloudtrail/), vous disposerez d'un environnement entièrement conforme. Tout cela utilise les services AWS natifs, ce qui vous évite quelques maux de tête supplémentaires.

Cette configuration fonctionnera comme une **couche de cohérence** en plus de vos pipelines de données bien gérés et matures.

## <h2>Conclusion</h2><br />
Dans cet article, nous avons supervisé le fonctionnement de la concurrence sur Redshift. Nous avons également vu comment analyser et améliorer les plans de charge des requêtes : les rendre plus rapides tout en consommant moins de puissance de traitement (vous pouvez interpréter cela comme ***réduire votre facture de cloud***).

Rappelez-vous simplement les tables de contrôle et les vues mentionnées, et vous serez prêt. Leur maîtrise vous aidera également à vérifier les éventuels conflits avec les tables de la requête.

Il est également conseillé d'exécuter périodiquement les commandes [ANALYZE](https://docs.aws.amazon.com/redshift/latest/dg/r_ANALYZE.html) et [VACUUM](https://docs.aws.amazon.com/redshift/latest/dg/r_VACUUM_command.html).

Si vous avez besoin d'aide pour transformer vos données, vous pouvez [nous contacter](https://calendly.com/dawrlog) pour toute question et même découvrir de nouvelles informations dont vous n'étiez pas conscient grâce à une meilleure compréhension de vos données.

À+!