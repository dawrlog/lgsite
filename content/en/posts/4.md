---
title: "Ways to Debug an Argo Workflow."
date: 2022-05-15
# weight: 1
# aliases: ["/first"]
tags: ["Kubernetes", "Argo", "Development"]
categories: ["Kubernetes", "Development"]
# series: ["Data Stack"]
author: "Daniel Paes"
ShowCodeCopyButtons: true
showToc: true
TocOpen: false
draft: false
hidemeta: false
comments: false
canonicalURL: "https://pipekit.io/blog/debug-argo-workflow"
disableHLJS: true # to disable highlightjs
# disableHLJS: false
disableShare: false
hideSummary: false
searchHidden: false
ShowReadingTime: true
ShowBreadCrumbs: true
ShowPostNavLinks: true
ShowWordCount: false
ShowRssButtonInSectionTermList: true
UseHugoToc: true
cover:
    image: "https://user-images.githubusercontent.com/78096758/217076830-73285776-ed08-4782-a0d0-e0a1226a0d38.png" # image path/url

---

Hello everyone, 

Today I would like to cover how to debug your [Argo workflows](https://argoproj.github.io/argo-workflows/), this comes handy when you need more details from your environment. Let’s check the two different approaches to debugging your Argo Workflow deployments. 

First, we’ll use the [Argo Command Line Interface](https://argoproj.github.io/argo-workflows/cli/argo/), or CLI for short. Argo’s CLI commands cover many of the more common errors you see with workflows, such as misconfigurations. Then, we’ll see how to debug workflows using the Argo Workflows UI. After we’re finished with Argo’s native tools, we’ll wrap up with how to debug your environment using kubectl.

## <h2>The Argo Workflows Command Line Interface</h2><br />
Argo Workflows command line interface (CLI) makes interactions with your cluster simple. Below I will present how to run Argo commands directly from your Kubernetes cluster on a namespace called argo. Remember that you can quickly adapt the code shown below to your environment. To reproduce it in your environment, change the option to `-n namespace` where `namespace` is the Kubernetes namespace where you have Argo deployed.

### <h3>Workflow Status with argo list </h3><br />
I want to cover two commands: `argo list` and `argo get`. With argo list you can quickly identify the status of all the workflows deployed on the supplied Kubernetes namespace. And you can take a close look at each workflow with the `argo get` command. While both controls aren't dependent on each other, their combination should answer most of your questions about running pods. I suggest using the `-A` flag as shown below. Doing so will widen the search of all your namespaces.

```sh 
argo list -A
``` 
As you can see, the command returns in a tabular format an updated status of all workflows in your environment by namespace. Having it presented like this is useful for automated health checks of your services. <br />
![Describe Output](https://user-images.githubusercontent.com/78096758/217077056-227dc5d5-0def-43a9-a0b3-e36de0039d22.png)
<br />
In cases where you want to focus your search on a specific namespace, the argo list command can also look for a single namespace thanks to the -n tag. This is useful when you have similar workflows deployed on different namespaces, a widespread scenario when managing [multi-tenant](https://whatis.techtarget.com/definition/multi-tenancy) environments. So, in cases like these, it's best to run argo list -n <namespace>, where <namespace> is the audited namespace. 

### <h3>Auditing Your Workflows with kubectl</h3><br />
There are scenarios where the Argo CLI output doesn't provide enough information for complete analysis of a pod. 

For example, in some cases, your Argo server won't be able to access your token key, and  It would be helpful to see how your control plane resolved this value. To do so, you can use kubectl commands to explore the configuration and health of your Argo Workflows instance. If dependent services aren't accessible, this method will help you.

Argo Workflows deploys three containers in each pod, and all are accessible using kubectl commands, as mentioned before.

### <h3>Getting your Argo deployment details with Kubernetes native commands </h3><br />
Here we’re looking at the k8s cluster as a whole. Using the command below, you can retrieve high-level info about the health of your deployed services.

```sh
kubectl get svc,po -n argo -o wide 
```

This presents you with information about the k8s control plane for your argo namespace. From here, you can use `kubectl describe` for more detailed information.

Argo and Kubernetes use the same pod name for their deployed components. Bear that in mind if you plan to automate your pipelines with a mix of kubectl and Argo Workflows CLI combinations for your observability strategy.

So, use `kubectl describe` to view how Kubernetes sees your pod deployment. This should resemble what you see on the Argo console UI.

Kubectl generates a lot of output, so pipe it through *more* or *less*.

```sh 
kubectl describe -n argo pod/dag-sum-pm8rp-2964331963 | less 
```
<br />

![Describe Output](https://user-images.githubusercontent.com/78096758/217077276-14039df0-187f-4afa-b17e-218d29662afb.png)

It is good to note that the pod name will be the same in both kubectl and Argo CLI commands. You won't have any surprises when choosing which one you prefer to use in your analysis as long as you use the same pod name. So, running ```kubectl logs -n argo pod/dag-swtgb-320908401 -c main``` or ```argo logs -n argo dag-swtgb dag-swtgb-320908401 -c main```; will then print the audit trace of your main container inside the Kubernetes pod ***dag-swtgb-320908401*** but using different command-line interfaces.

You can also explore the init and wait containers the same way as using the Argo workflow CLI commands. Though slightly different, it will return the detailed data from Kubernetes deployments. It's a personal choice whether you want to use kubectl or Argo native commands.

### <h3>More Detail with argo get</h3><br />
Once you have the service you need and its namespace, you can see more details with the *argo get* command. Executing the following command will give you a consolidated message per step of the Argo workflow. In our example, the workflow `dag-swtgb` exists on the argo namespace.

```sh 
argo get -n argo dag-swtgb
``` 

Running the same command without the `-o yaml` option will return an output like the one below with a more consolidated view. It's helpful to see the message produced by your problematic pods.


![Describe Output](https://user-images.githubusercontent.com/78096758/217077803-21d66573-2398-4912-857e-507be51a3b89.png)
_Argo get command output with errors_

### <h3>‍Go Deeper with argo logs </h3><br />

Argo deployments share the workflow deployments of every pod over the main, init, and wait containers. I will cover how to access them using kubectl in a bit, but you can also access them using Argo logs on the desired pod.

I should also point out that if your pod didn't start, those containers wouldn't start either. 

You can follow a workflow’s logs with argo logs.

Consider this command line session:

```sh
argo -n argo submit sum.yaml 
```

and its output:

```
Name:                dag-sum-gm5sv
Namespace:           argo
ServiceAccount:      unset (will run with the default ServiceAccount)
Status:              Pending
Created:             Tue Apr 05 12:53:30 -0400 (now)
Progress:

This workflow does not have security context set. You can run your workflow pods more securely by setting it.
Learn more at https://argoproj.github.io/argo-workflows/workflow-pod-security-context/ 
```

When you submit a new workflow, Argo gives you its name.

Pass that name to argo logs with the namesapce and the `–-follow` option:

```sh
argo -n argo logs dag-sum-gm5sv --follow 
```

Output:

```
dag-sum-gm5sv-899595302: time="2022-04-05T16:53:32.791Z" level=info msg="capturing logs" argo=true
dag-sum-gm5sv-899595302: 2
dag-sum-gm5sv-508066804: time="2022-04-05T16:53:33.072Z" level=info msg="capturing logs" argo=true
dag-sum-gm5sv-508066804: 2
dag-sum-gm5sv-844819: time="2022-04-05T16:53:42.984Z" level=info msg="capturing logs" argo=true
dag-sum-gm5sv-844819: 4 
```

Argo will echo the logs to the screen as the workflow progresses.

If you don’t want to use the command line, you can do this via the Argo Workflows UI, too.

## <h2>View Your Argo Workflows Events in the Console UI</h2><br />
Last, but not least; you can also debug your Argo environment using the console UI it provides. This service is accessible by following one of the steps mentioned in their docs, but in this case, we will do a simple port forward between the Kubernetes deployment and the host. The code presented here can run flawlessly on Linux and macOS machines. These environments allow you to bind the port between your workstation and your Kubernetes cluster as a background process with this command: <br />

```sh
kubectl -n argo port-forward svc/argo-server 2746:2746 &. 
```
With the service accessible from the host, you can point any web browser to the address `https://localhost:2746`.

![Describe Output](https://user-images.githubusercontent.com/78096758/217078031-42a1dc57-a062-4f74-8ccb-2c9cc85f6b03.png)

## <h3>Conclusion</h3><br />
You saw how to debug Argo Workflows components using the Argo CLI and Argo UI, or kubectl commands. The steps I described here can help you understand what's happening in your environment. 

See you next time! 

Article originally posted at [Pipekit blog](https://pipekit.io/blog/debug-argo-workflow)