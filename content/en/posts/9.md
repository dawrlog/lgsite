---
title: "Redshift Query Queues: The Complete Guide"
date: 2021-11-19
# weight: 1
# aliases: ["/first"]
tags: ["Data Warehouse", "Best Practices", "AWS", "Redshift"]
categories: ["Data Modeling"]
# series: ["Data Stack"]
author: "Daniel Paes"
# author: ["Me", "You"] # multiple authors
showToc: true
TocOpen: false
draft: false
hidemeta: false
comments: false
canonicalURL: "https://blog.panoply.io/the-redshift-query-queues-challenges-and-some-tips"
disableHLJS: true # to disable highlightjs
disableShare: false
disableHLJS: false
hideSummary: false
searchHidden: false
ShowReadingTime: true
ShowBreadCrumbs: true
ShowPostNavLinks: true
ShowWordCount: false
ShowRssButtonInSectionTermList: true
UseHugoToc: true
cover:
    image: "https://user-images.githubusercontent.com/78096758/217089342-26bc2683-98d9-4b10-b2b1-273d2a34ba9b.png" 
---

Hey everyone, hope everything is well. 

Even the most potent database is still prone to the terrifying error any database system can face: **_query bottlenecks_**.

Sometimes the systems that manage our queries can't process in the same way as we do. So our questions return accurate results as a result of extra processing power.

In this article, I'll present how Redshift query queues work. We'll also cover how concurrency works at a high level on Redshift.

This intel will become handy as we go further down the rabbit hole and oversee the deployment of a good—though sometimes threatening—friend, **workload management (or WLM)** on Redshift.

We'll finish with a quick conclusion of what we saw and some techniques for query optimizations.

Query optimizations are very handy as it helps on cleaning bad code. Then increasing your transformations' speed, making it possible to explore more data with less. In short, good old [data frugality](https://hellofuture.orange.com/en/towards-a-less-data-and-energy-intensive-ai/).

## <h2>What is Redshift, and how does query processing work?</h2><br />

Redshift is Amazon's flavor of a massively parallel processing (or MPP) database system.

This kind of database is the top choice for storing data warehouses thanks to its capabilities of processing massive amounts of data in parallel. As for the other two major cloud providers, there's [BigQuery](https://cloud.google.com/bigquery) on Google Cloud Platform and [Synapse Analytics](https://azure.microsoft.com/en-ca/services/synapse-analytics/) on Microsoft Azure.

Now let's look more in-depth at the process of querying.

Query processing
Once the query is started (either by the **console** or by pragmatic access—and both **API** and **CLI commands** follow the same way), it generates a **query plan**, which is the query translation made by the parser while extracting the data from the nodes.

With this execution blueprint, we can start to inspect the compute bottlenecks on your code.

Here's an example of an **EXPLAIN** Redshift command:

```sql
explain

select lastname, catname, venuename, venuecity, venuestate, eventname,
month, sum(pricepaid) as buyercost, max(totalprice) as maxtotalprice
from category join event on category.catid = event.catid
join venue on venue.venueid = event.venueid
join sales on sales.eventid = event.eventid
join listing on sales.listid = listing.listid
join date on sales.dateid = date.dateid
join users on users.userid = sales.buyerid
group by lastname, catname, venuename, venuecity, venuestate, eventname, month
having sum(pricepaid)>9999
order by catname, buyercost desc;
```

From the **EXPLAIN** results above, I want to identify the tables: **_category, venue, sales, listing, date, and users_**. Each one of them uses the **INNER JOIN** clause.

Redshift's power relies on heavy processing, so the bigger those tables are, the better for you, computationally speaking.

But how can you know that? Going deeper, how can you identify the smaller tables for you to take the necessary metrics and measures so important for your KPIs?

Here's where the **query plan** comes in handy; below, you can see all the steps Redshift executes based on the SQL you wrote. So here's where Redshift tells you if what you wrote is what Redshift understood.

Here is the result of the above **EXPLAIN** command:

![queryplan](https://user-images.githubusercontent.com/78096758/217089951-c6cedc17-23d3-4a99-b1f3-bae48235d2ba.png)
_Query plan results._

Now that we know how to create the query plan, we can go deeper into query optimization—which is nothing more than refactoring your queries to lower the processing costs described by the query plan steps.

<br /><br />

## <h2>What is workload management, or WLM?</h2><br />
One of the faster ways of managing your query workflows is called workload management. With this feature on, you won't sacrifice being able to answer quick questions due to long-running processes, as it enables flexibility while managing your workloads.

_Let's imagine the following scenario:_
- Your lead data scientist is deploying some machine learning models to detect possible fraudulent activities.
- Those activities need to be cross-referenced with the geographical location of the last transactions.
- Then those chaotic independent microservices start to run on your Redshift clusters at the exact time that your KPIs trigger new processes on the same Redshift cluster.

Fun times, right?

WLM comes to the rescue, as it creates what is called **query queues** at runtime. WLM groups these queues by a query group label defined by the user before the query execution.

These queues have concurrency levels, meaning the number of workloads started at the same time.
<br /><br />

## <h2>Let's get used to Workload Manager, or WLM</h2><br />
WLM comes with two types of implementations; [automatic](https://docs.aws.amazon.com/redshift/latest/dg/automatic-wlm.html) where Redshift takes the charge of handling your query memory and concurrency allocation, and [manual](https://docs.aws.amazon.com/redshift/latest/dg/cm-c-defining-query-queues.html) where you provide those values instead.

Below I want to share the helpful **_system tables and views_** that should be used as starting points when needing to enhance, or simply audit, your WLM workloads.

- [STL_WLM_ERROR](https://docs.aws.amazon.com/redshift/latest/dg/r_STL_WLM_ERROR.html)
- [STL_WLM_QUERY](https://docs.aws.amazon.com/redshift/latest/dg/r_STL_WLM_QUERY.html)
- [STV_WLM_CLASSIFICATION_CONFIG](https://docs.aws.amazon.com/redshift/latest/dg/r_STV_WLM_CLASSIFICATION_CONFIG.html)
- [STV_WLM_QUERY_QUEUE_STATE](https://docs.aws.amazon.com/redshift/latest/dg/r_STV_WLM_QUERY_QUEUE_STATE.html)
- [STV_WLM_QUERY_STATE](https://docs.aws.amazon.com/redshift/latest/dg/r_STV_WLM_QUERY_STATE.html)
- [STV_WLM_QUERY_TASK_STATE](https://docs.aws.amazon.com/redshift/latest/dg/r_STV_WLM_QUERY_TASK_STATE.html)
- [STV_WLM_SERVICE_CLASS_CONFIG](https://docs.aws.amazon.com/redshift/latest/dg/r_STV_WLM_SERVICE_CLASS_CONFIG.html)
- [STV_WLM_SERVICE_CLASS_STATE](https://docs.aws.amazon.com/redshift/latest/dg/r_STV_WLM_SERVICE_CLASS_STATE.html)

<br /><br />

## <h2>The do's and don'ts of concurrency scaling</h2><br />
Once you have your WLM turned on, you enable one handy feature used on massive processing: **concurrent scaling**! You will perceive the gains from the writing process into the target for consistency on higher throughput with multiple sessions requests.

Still, when the feature is active, concurrency scaling is applied for both **_read_** and **_write_** operations. It also supports SQL Data Manipulation Language statements, the good ol' **INSERT**, **DELETE** and **UPDATE**. It also supports the **CREATE** statement and [Redshift COPY](https://docs.aws.amazon.com/redshift/latest/dg/r_COPY.html); which gets you cover for most of your **daily data loads**.

The more critical limitations from concurrency scaling are its limitation of ANALYZE for the COPY commands and not being able to use COPY from Redshift Spectrum or when you're querying data from your HDFS storage in your EMR clusters. Being that the COPY command is the suggested option to import massive data into native Redshift tables, not running it in parallel can limit the utilization of the COPY command for your use case.

It's also relevant to remember that you need to confirm if the region where your Redshift cluster resides has the concurrency scaling feature; for a quick reference, take a look here.

Change the **Concurrency Scaling Mode** option to **auto** on your WLM queue, and by doing so, you'll enable the routing of your queries into the concurrency scaling clusters.
<br /><br />

## <h2>Getting statistics for your WLM</h2><br />
With your WLM enabled and your queues with the "Concurrency Scaling Mode" turned to auto, you can track what's going on in your cluster.

To do so, you can go to your query editor of choice or the Redshift console and execute the following query:
<br /><br />

***Query for monitoring concurrent queues***

``` sh 
SELECT w.service_class AS queue
, q.concurrency_scaling_status
, COUNT( * ) AS queries
, SUM( q.aborted ) AS aborted
, SUM( ROUND( total_queue_time::NUMERIC / 1000000,2 ) ) AS queue_secs
, SUM( ROUND( total_exec_time::NUMERIC / 1000000,2 ) ) AS exec_secs
FROM stl_query q
JOIN stl_wlm_query w
USING (userid,query)
WHERE q.userid > 1
AND q.starttime > # Time on format: 'YYYY-MM-DD 24HH:MI:SS'
AND q.endtime < # Time on format: 'YYYY-MM-DD 24HH:MI:SS'
GROUP BY 1,2
ORDER BY 1,2;
```

The query results will provide you with a full spectrum of what's happening on your cluster, granting all the necessary information from the Redshift cluster management perspective. All this information is helpful when investigating which sessions are active or not on your sets (you can check how the result would look like below).

![concurrent](https://user-images.githubusercontent.com/78096758/217090175-daebfb60-fb6e-4a39-83f8-838eae68fb11.png)
_Query results_

In addition to the metrics collected by [AWS CloudWatch](https://aws.amazon.com/cloudwatch/) and [AWS CloudTrail](https://aws.amazon.com/cloudtrail/), you'll have a fully compliant environment. All of it is using native AWS services, saving you some extra headaches.

This configuration will work as a **consistency layer** in addition to your well-managed and mature data pipelines.

## <h2>Conclusion</h2><br />

In this article, we oversaw how concurrency on Redshift works. We also looked at how to analyze and improve queries load plans: making them faster while consuming less processing power (you can interpret this as ***making your cloud bill smaller***).

Just remember the mentioned control tables and views, and you'll be all set. Mastering them will also help while verifying any conflicts with the tables on the query.

It's also a good idea to run the [ANALYZE](https://docs.aws.amazon.com/redshift/latest/dg/r_ANALYZE.html) and [VACUUM](https://docs.aws.amazon.com/redshift/latest/dg/r_VACUUM_command.html) commands periodically.

For further help transforming your data, you can [reach out to us](https://calendly.com/dawrlog) with any questions you have and even discover new info you weren't aware of with a better insight from better understanding your data.

See you guys next time! 

Article originally posted at [Panoply blog](https://blog.panoply.io/the-redshift-query-queues-challenges-and-some-tips)