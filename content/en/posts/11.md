---
title: "AWS Redshift Spectrum, Athena, and S3: Everything You Need to Know"
date: 2021-07-08
# weight: 1
# aliases: ["/first"]
tags: ["Data Warehouse", "AWS", "Data Modeling", "Redshift", "Athena", "S3"]
categories: ["Data warehouse", "Data Modeling", "Cloud"]
# series: ["Data Stack"]
author: "Daniel Paes"
# author: ["Me", "You"] # multiple authors
showToc: true
TocOpen: false
draft: false
hidemeta: false
comments: false
canonicalURL: "https://blog.panoply.io/the-spectrum-of-redshift-athena-and-s3"
disableHLJS: true # to disable highlightjs
disableShare: false
disableHLJS: false
hideSummary: false
searchHidden: false
ShowReadingTime: true
ShowBreadCrumbs: true
ShowPostNavLinks: true
ShowWordCount: false
ShowRssButtonInSectionTermList: true
UseHugoToc: true
cover:
    image: "https://user-images.githubusercontent.com/78096758/217091701-9777080f-4d8b-4bf9-b9fe-5dead25dd10f.png" 
---

Hey everyone, today I would like to present you how to explore your raw data stored by [AWS S3](https://aws.amazon.com/s3/) by using AWS managed analytical managed services. Today we will cover both [AWS Redshift Spectrum](https://docs.aws.amazon.com/redshift/latest/dg/c-using-spectrum.html#c-spectrum-overview) and [AWS Athena](https://aws.amazon.com/athena/) on our tutorial.

One of the significant challenges to data-driven companies comes when integrating different application systems.

Major public cloud providers, such as [Amazon Web Services](https://aws.amazon.com/) or [Google Cloud Platform](https://cloud.google.com/docs/overview), offer robust products that are ready for your analytics needs. But when it comes to exploring your data, things might not be that simple.

Your source data often comes from files with unknown formats of data, which makes an analyst's job a nightmare.

Some cases could be more fluid in this integration, such as when your data has nested values. Exploding complex structures, such as JSON files, into a tabular format, can consume most of your time when you're exploring new data.

That's where ***AWS Redshift Spectrum*** and ***AWS Athena*** shine. They let you use SQL to analyze data without changing it from the source. There's no need for complex Python code if you don't want to use it on initial data profiling tasks.

Pretty neat, right?

This article will show you how to explore your data on Amazon S3 using Athena and Redshift Spectrum. Below, you'll find the necessary steps to create a table on the [AWS Glue catalog](https://docs.aws.amazon.com/prescriptive-guidance/latest/serverless-etl-aws-glue/aws-glue-data-catalog.html) and use it to access your data in Amazon S3.
<br /><br />

## <h2>How do Redshift Spectrum, AWS Athena & AWS S3 fit together?</h2><br />

While Amazon's data products aren't quite as extensive as its famous ecommerce shop, there's still a lot going on. 
<br /><br />

## <h3> Redshift Spectrum </h4> <br />
Spectrum is an Amazon Redshift component that allows you to query files stored in Amazon S3, this is done by creating a new database pointing to your AWS S3 storage bucket. 

Your team can narrow its search by querying only the necessary columns for your analysis. Also, it's possible to consult existing tables from your Redshift cluster, which means that instead of querying the full table all the time, you can select the required columns for your report using SQL.

So when you're querying your data, you get only the needed columns from your data instead of returning unnecessary fields and rows. The also opens up the possibility of querying data stored directly on Amazon S3.
<br /><br />

## <h3> AWS Athena </h4> <br />
Athena makes it easier to create shareable SQL queries among your teams—unlike Spectrum, which needs Redshift. You can then create and run your workbooks without any cluster configuration.

Athena makes it possible to achieve more with less, and it's cheaper to explore your data with less management than Redshift Spectrum.

## <h3> AWS S3  </h4> <br />
AWS S3 is the managed [object storage](https://www.techopedia.com/definition/29510/object-storage) option that Amazon offers. It's the best option to store your semi-structured data, such as server logs from your applications.

S3 also allows **_delete protection_** and **_version control_** of your objects, making your data safer and easier to track back to its original source.

## <h2> How to create tables from files </h2><br />
Now that you have an overall idea of each product, it's time to get your hands dirty and create some tables!

We'll use a sample CSV dataset for our tutorial, which you can [download here](https://people.sc.fsu.edu/~jburkardt/data/csv/csv.html).


We'll also assume that you have your Redshift cluster ready with the necessary [IAM roles]() attached to it (when using Redshift Spectrum).

You'll also need your [AWS bucket](https://docs.aws.amazon.com/AmazonS3/latest/userguide/create-bucket-overview.html) set up with your data configured and the required permissions to create your data catalog; more details can be found at [Athena IAM Data Catalog policy](https://docs.aws.amazon.com/athena/latest/ug/datacatalogs-iam-policy.html) page.

Okay, so far, so good! Let's move on to creating the tables.

First, you need to create the database where the tables will be stored.

For this tutorial, we'll count on AWS Glue Data Catalog for this job. Just remember that other options are available, such as the [Hive metastore](https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-metastore-external-hive.html).

AWS Glue Data Catalog is a better option if you want to have fluid integration with additional data sources without starting extra services.

Here is how to create **database on AWS Athena**:

```sql
CREATE DATABASE IF NOT EXISTS ext_data_suppliers
  COMMENT 'Landing Zone for S3 buckets loaded by external Data Suppliers'
  LOCATION 's3://test-12343210/';
```

Here's the **Redshift Spectrum** version of it:

```sql
create external schema ext_data_suppliers from data catalog 
database 'ext_data_suppliers'
iam_role 'arn:aws:iam::123456789012:role/RSRoleApiData'
create external database if not exists;
```

As you can see in both cases, your code will create a Glue catalog database if one doesn't exist already.

Once you have that, you'll need the table definition, which will let you query the data directly from the file.

At this stage, I recommend not doing any transformations on the data because a minor modification. As on this data layer we want to be as close to its data source as possible, even a simple datatype conversion can result in the loss of data. So let's avoid that, especially in the early stages.

Now, let's create a table definition that'll contain the data.

Below, you can see the Athena version:
```sql
CREATE EXTERNAL TABLE IF NOT EXISTS ext_data_suppliers.zillow_sample_file 
( `index` int, 
  `liv_space_in_sqft` int, 
  `beds` int, 
  `baths` int, 
  `zip` int, 
  `year` int, 
  `list_price_in_usd` int )
ROW FORMAT SERDE 
  'org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe'
WITH SERDEPROPERTIES 
  ( 'serialization.format' = ',', 'field.delim' = ',') 
LOCATION 's3://test-12343210/'
TBLPROPERTIES ('has_encrypted_data'='false');
```

And here's the Spectrum version:
```sql
CREATE EXTERNAL TABLE ext_data_suppliers.zillow_sample_file 
( index int, 
liv_space_in_sqft int, 
beds int, 
baths int, 
zip int, 
year int, 
list_price_in_usd int )
ROW FORMAT SERDE 
   'org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe'
WITH SERDEPROPERTIES 
   ( 'serialization.format' = ',', 'field.delim' = ',') 
LOCATION 's3://test-12343210/';
```
<br />

## <h2> So, which should you choose: Spectrum or Athena? </h2><br />
Most data from data suppliers isn't optimized to answer the questions you may have. As this data is in a raw state, tools like AWS Athena or AWS Redshift Spectrum will make your exploration tasks much more straightforward.

Both tools allow you to explore your data without loading it into a database. All you need to do is say what your data structure is and where it resides. After that, you're good to go—no more delays on your data pipelines to start creating your dashboards. As your data becomes available on your Amazon S3 bucket, your team can consume it right away.

You can run federated queries on both services. These queries allow the use of the same SQL script to correlate data from structured relational sources, such as MySQL and Postgres.

My advice? **_Choose Athena if you don't have a Redshift cluster already in place._**

With Athena, it becomes easier to create shareable queries among your team without managing extra services and raising your cloud bill unnecessarily.
<br /><br />

## <h3>Summing it up and going deeper</h3><br />
To recap, we've covered 2 important topics:

The benefits of having a data exploration tool that allows your analysts to run SQL commands on top of your object-storage-type solution.
Running SQL commands on files stored in Amazon S3, using Athena and Redshift Spectrum.

As you saw, both scripts are very similar. In both, we used [serialization/deserialization](https://docs.aws.amazon.com/athena/latest/ug/supported-serdes.html) (SerDe for short) to create a table-like structure correctly. This structure lets you access the data in the CSV format without loading it into native tables.

Here's another thing I'd like you to remember: Grant only the [necessary permissions](https://docs.aws.amazon.com/athena/latest/ug/datacatalogs-example-policies.html) to services. Narrowing access to your services will help you sleep better. 

For further help transforming your data, you can [reach out to us](https://calendly.com/dawrlog) with any questions you have and even discover new info you weren't aware of with a better insight from better understanding your data.

See you guys next time! 

Article originally posted at [Panoply blog](https://blog.panoply.io/the-spectrum-of-redshift-athena-and-s3)