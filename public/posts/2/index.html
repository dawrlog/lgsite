<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Archiving Argo Workflows: Postgres Database Setup | Dataware Logistics</title>
<meta name="keywords" content="Kubernetes, Argo, Development, Data Warehouse, Best Practices">
<meta name="description" content="Hello everyone, I hope you are doing well!
If you’re familiar with Argo Workflows, you already know that it can drive your CI/CD pipelines, manage your ETL processes, and orchestrate any set of tasks you can imagine for a Kubernetes cluster. But did you know that Argo knows how to archive the results of its workflows to a SQL database, too?
In this post, I&rsquo;ll show how Argo Workflows archives workflow state into persistent storage using a Postgres database.">
<meta name="author" content="Daniel Paes">
<link rel="canonical" href="https://pipekit.io/blog/archiving-argo-workflows-postgres-database-setup">
<meta name="google-site-verification" content="4599922566">
<link crossorigin="anonymous" href="/assets/css/stylesheet.css" rel="preload stylesheet" as="style">
<link rel="icon" href="https://www.dawrlog.com/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://www.dawrlog.com/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://www.dawrlog.com/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://www.dawrlog.com/apple-touch-icon.png">
<link rel="mask-icon" href="https://www.dawrlog.com/apple-touch-icon.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://www.dawrlog.com/posts/2/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="Archiving Argo Workflows: Postgres Database Setup" />
<meta property="og:description" content="Hello everyone, I hope you are doing well!
If you’re familiar with Argo Workflows, you already know that it can drive your CI/CD pipelines, manage your ETL processes, and orchestrate any set of tasks you can imagine for a Kubernetes cluster. But did you know that Argo knows how to archive the results of its workflows to a SQL database, too?
In this post, I&rsquo;ll show how Argo Workflows archives workflow state into persistent storage using a Postgres database." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://www.dawrlog.com/posts/2/" />
<meta property="og:image" content="https://assets.website-files.com/6238902a290688c9a1ad26ea/6293bd541bf0c5e5cc82d1e7_1.jpg" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-04-11T00:00:00+00:00" />
<meta property="article:modified_time" content="2022-04-11T00:00:00+00:00" />

<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="https://assets.website-files.com/6238902a290688c9a1ad26ea/6293bd541bf0c5e5cc82d1e7_1.jpg" />
<meta name="twitter:title" content="Archiving Argo Workflows: Postgres Database Setup"/>
<meta name="twitter:description" content="Hello everyone, I hope you are doing well!
If you’re familiar with Argo Workflows, you already know that it can drive your CI/CD pipelines, manage your ETL processes, and orchestrate any set of tasks you can imagine for a Kubernetes cluster. But did you know that Argo knows how to archive the results of its workflows to a SQL database, too?
In this post, I&rsquo;ll show how Argo Workflows archives workflow state into persistent storage using a Postgres database."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://www.dawrlog.com/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Archiving Argo Workflows: Postgres Database Setup",
      "item": "https://www.dawrlog.com/posts/2/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Archiving Argo Workflows: Postgres Database Setup",
  "name": "Archiving Argo Workflows: Postgres Database Setup",
  "description": "Hello everyone, I hope you are doing well!\nIf you’re familiar with Argo Workflows, you already know that it can drive your CI/CD pipelines, manage your ETL processes, and orchestrate any set of tasks you can imagine for a Kubernetes cluster. But did you know that Argo knows how to archive the results of its workflows to a SQL database, too?\nIn this post, I\u0026rsquo;ll show how Argo Workflows archives workflow state into persistent storage using a Postgres database.",
  "keywords": [
    "Kubernetes", "Argo", "Development", "Data Warehouse", "Best Practices"
  ],
  "articleBody": "Hello everyone, I hope you are doing well!\nIf you’re familiar with Argo Workflows, you already know that it can drive your CI/CD pipelines, manage your ETL processes, and orchestrate any set of tasks you can imagine for a Kubernetes cluster. But did you know that Argo knows how to archive the results of its workflows to a SQL database, too?\nIn this post, I’ll show how Argo Workflows archives workflow state into persistent storage using a Postgres database. To do so, I’ll present a quick summary of Argo components while showing what it means to have your workflow archived. We’ll deploy Argo Workflows alongside a Postgres database on a local Kubernetes instance using k3d. Finally, we’ll discuss some important security considerations for your Argo Workflows deployment.\nSo, let’s get started.\nWhat is the Archive Option in Argo Workflows? The ability to store past workflow runs provides you with an accurate record of your past workflow states. This blueprint is a game changer, as it makes it possible to provision your task sets based on real-time metrics, such as spikes in processing needs from past deployments.\nThe workflow archive option stores your workflow states in either MySQL or Postgres. Once you have archives configured, you can use them to better understand how your jobs run and where you might be able to improve.\nFor example, they can help you know when it’s a good idea to scale your traffic with the help of temporary instances, which will also have their states stored on the same database. With all your states held over time, you can apply rules to adjust your cluster size based on previous usage; a good time series analysis could even save you some money in the end.\nThe archive stores only the previous workflow states, not their detailed instance logs. Another thing to keep in mind is detailed audit logs. The artifact store option handles the detailed logs persistent option, storing it locally by [MinIO](https://min.io/). But you can also configure any other object storage option. This is covered in the [Argo official documetation](https://argoproj.github.io/argo-workflows/configure-artifact-repository/), where you can see how to use options such as [Google Cloud Storage](https://cloud.google.com/storage) buckets or [AWS S3](https://aws.amazon.com/s3/). But before we start on the technical implementation, let’s have a quick refresher on the components of Argo Workflows. It’s necessary to know how they correlate with the persistent storage for your archived workflows; this image from the Argo Workflows documentation presents an overview of the environment where a workflow resides:\nSource: Argo Workflow Github repository\nHow to Deploy Argo Workflows with Persistent Storage\nNow that we know what’s in store for us let’s get started. We’ll be using k3d to manage our local Kubernetes environment (instead of minikube and VirtualBox). In addition to k3d, you’ll need to install Docker as an additional dependency. Using kubectl to interact with your Kubernetes cluster works fine, too. As for our tutorial, we’ll be using local Kubernetes deployment scripts.\nFirst, we’ll start our local control plane with the following command:\nk3d cluster create cluster-demo The successful creation will provide a log similar to this one:\nCreating the cluster\nOnce we have our `cluster-demo`, we'll deploy our Argo Workflows instance. To install Argo Workflows, you'll need to execute the following commands: kubectl create ns argo kubectl apply -n argo -f https://raw.githubusercontent.com/argoproj/argo-workflows/master/manifests/quick-start-postgres.yaml The first one creates a namespace called argo in your cluster, and the following line will deploy the Argo Workflows components on your cluster, as you can see below:\nDeployments made on the cluster\nCreating the workflow-controller To run the workflow with the archive option, you must first change the persistence configuration to archive:true on your Argo server deployment. Changing it will tell your Argo server to store your workflow execution states into the database reported by the key postgresql.\nWe’ll apply a new ConfigMap into our current Kubernetes argo namespace with the Postgres instance to store your archived workflows. You can then archive your workflows by using the archiveLogs option.\nWe had a Postgres instance deployed with the Quickstart YAML we used earlier. You’ll need it only to apply the following configuration to your deployment. Changing this configuration enables your Argo server deployment to accept the archiveLocation.archiveLogs notation while creating your workflows. We’ll start by creating a new workflow-controller-configmap.yml with the following content and saving it locally:\napiVersion: v1 kind: ConfigMap metadata: name: workflow-controller-configmap data: persistence: | connectionPool: maxIdleConns: 100 maxOpenConns: 0 connMaxLifetime: 0s nodeStatusOffLoad: true archive: true archiveTTL: 7d postgresql: host: postgres port: 5432 database: postgres tableName: argo_workflows userNameSecret: name: argo-postgres-config key: username passwordSecret: name: argo-postgres-config key: password retentionPolicy: | completed: 10 failed: 3 errored: 3 Deploy Your Environment with kubectl We’ll expose the Argo Workflows web UI using a load balancer on our argo namespace. The load balancer will expose the pod executing the web-facing component to connections made from outside Kubernetes.\nkubectl apply -n argo -f workflow-controller-configmap.yml Your Argo server will restart with the new configuration in a couple of minutes. Feel free to check its status by running kubectl get -n argo svc,pod on your Kubernetes cluster.\nkubectl get -n argo svc,pod You can then bind your Kubernetes cluster and your host to port 2746 by running the following on your cluster:\nkubectl -n argo port-forward deployment/argo-server 2746:2746 \u0026 Congratulations, you just deployed Argo Workflows on a k3d cluster. To confirm that your local instance is up and running, go to https://localhost:2746.\nArgo Workflows user info UI page Testing Your Deployment\nCongratulations on installing your Argo Workflows instance on your local Kubernetes cluster with the archive option. And now that we have checked that off our list, let’s archive our workflows. Adding the archiveLogs annotation lets you specify which ones you want to archive, as demonstrated in the following template, which we’ll call workflow-archive.yml.\napiVersion: argoproj.io/v1alpha1 kind: Workflow metadata: generateName: archive-location- spec: archiveLogs: true # enables logs for this workflow entrypoint: whalesay templates: - name: whalesay container: image: docker/whalesay:latest command: [cowsay] args: [\"hello world\"] We need to execute argo submit -n argo --watch -f workflow-archive.yml on a terminal to deploy it.\nargo submit -n argo --watch -f workflow-archive.yml By doing so, you’ll start the archive-location workflow under the argo namespace; the following output confirms that our example ran successfully:\nArgo Workflows archive example run output log It doesn’t change on the command line; however, as we have persistent storage for our workflows, you can see their previous states on the console UI. That’ll give you the previous workflow states that ran with the archive options enabled—and going to the Argo Workflows console UI at https://localhost:2746, as we saw before, you can access the archived workflow UI option from the left menu bar’s icons. Once you are there, you can see all the past executions of a workflow. Your workflow history can be found in the UI under “Archived Workflows” (see below).\nArgo Workflows archived workflow console Security Best Practices for Archiving Argo Workflows in Postgres\nIn our work, we deployed an Argo instance with the archive option configured with a Postgres database. As mentioned previously, this code isn’t production-ready. As a next step, I suggest managing your access tokens to secure your Argo instance.\nA good practice is to avoid hardcoded values for server runtime information when possible. Your infrastructure should generate data like your Postgres hostname on runtime instead of having it hardcoded. Your infrastructure should use secrets to store sensitive information like repository access keys.\nPostgres Archiving\nTake a look at this introduction about Secrets and configmaps in Kubernetes, for more details on what Kubernetes information should be discreet. Adopting security best practices like this in the early stages is easier for both your users and developers as you start to scale. In addition, having your configuration automated ends up narrowing the attack surface of your environment while also reducing infrastructure management tasks.\nHere’s a helpful blog post with more Argo security best practices from the Argo Workflows maintainer, Alex Collins.\nConclusion\nWe deployed Argo Workflows locally and archived a workflow using a Postgres database in this post. The scripts here are good starting points to understand and experiment with the archive option of Argo Workflows, but keep in mind that some critical factors are missing for a fully cloud native environment.\nSee you guys next time!\n",
  "wordCount" : "1374",
  "inLanguage": "en",
  "image":"https://assets.website-files.com/6238902a290688c9a1ad26ea/6293bd541bf0c5e5cc82d1e7_1.jpg","datePublished": "2022-04-11T00:00:00Z",
  "dateModified": "2022-04-11T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Daniel Paes"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://www.dawrlog.com/posts/2/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Dataware Logistics",
    "logo": {
      "@type": "ImageObject",
      "url": "https://www.dawrlog.com/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://www.dawrlog.com/" accesskey="h" title="Dataware Logistics (Alt + H)">Dataware Logistics</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
                <ul class="lang-switch"><li>|</li>
                    <li>
                        <a href="https://www.dawrlog.com/fr/" title="French"
                            aria-label=":fr:">🇫🇷</a>
                    </li>
                </ul>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://www.dawrlog.com/about" title="About">
                    <span>About</span>
                </a>
            </li>
            <li>
                <a href="https://www.dawrlog.com/posts/" title="Posts">
                    <span>Posts</span>
                </a>
            </li>
            <li>
                <a href="https://calendly.com/dawrlog" title="Contact">
                    <span>Contact</span>&nbsp;
                    <svg fill="none" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round"
                        stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12">
                        <path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"></path>
                        <path d="M15 3h6v6"></path>
                        <path d="M10 14L21 3"></path>
                    </svg>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://www.dawrlog.com/">Home</a>&nbsp;»&nbsp;<a href="https://www.dawrlog.com/posts/">Posts</a></div>
    <h1 class="post-title">
      Archiving Argo Workflows: Postgres Database Setup
    </h1>
    <div class="post-meta"><span title='2022-04-11 00:00:00 +0000 UTC'>April 11, 2022</span>&nbsp;·&nbsp;7 min&nbsp;·&nbsp;Daniel Paes

</div>
  </header> 
<figure class="entry-cover"><img loading="lazy" src="https://assets.website-files.com/6238902a290688c9a1ad26ea/6293bd541bf0c5e5cc82d1e7_1.jpg" alt="">
        
</figure><div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><nav id="TableOfContents">
  <ul>
    <li><a href="#h2what-is-the-archive-option-in-argo-workflowsh2-br-"><h2>What is the Archive Option in Argo Workflows?</h2> <br /></a></li>
    <li><a href="#h2how-to-deploy-argo-workflows-with-persistent-storageh2br-"><h2>How to Deploy Argo Workflows with Persistent Storage</h2><br /></a></li>
    <li><a href="#h2creating-the-workflow-controller-h2br-"><h2>Creating the workflow-controller </h2><br /></a></li>
    <li><a href="#h2testing-your-deploymenth2br-"><h2>Testing Your Deployment</h2><br /></a></li>
    <li><a href="#h2security-best-practices-for-archiving-argo-workflows-in-postgresh2br-"><h2>Security Best Practices for Archiving Argo Workflows in Postgres</h2><br /></a></li>
    <li><a href="#h2conclusionh2br-"><h2>Conclusion</h2><br /></a></li>
  </ul>
</nav>
        </div>
    </details>
</div>

  <div class="post-content"><p>Hello everyone, I hope you are doing well!</p>
<p>If you’re familiar with <a href="https://argoproj.github.io/workflows/">Argo Workflows</a>, you already know that it can drive your CI/CD pipelines, manage your ETL processes, and orchestrate any set of tasks you can imagine for a Kubernetes cluster. But did you know that Argo knows how to archive the results of its workflows to a SQL database, too?</p>
<p>In this post, I&rsquo;ll show how Argo Workflows archives workflow state into persistent storage using a Postgres database. To do so, I&rsquo;ll present a quick summary of Argo components while showing what it means to have your workflow archived. We&rsquo;ll deploy Argo Workflows alongside a Postgres database on a local Kubernetes instance using <a href="https://k3d.io/v5.3.0/">k3d</a>. Finally, we’ll discuss some important security considerations for your Argo Workflows deployment.</p>
<p>So, let&rsquo;s get started.</p>
<h2 id="h2what-is-the-archive-option-in-argo-workflowsh2-br-"><h2>What is the Archive Option in Argo Workflows?</h2> <br /><a hidden class="anchor" aria-hidden="true" href="#h2what-is-the-archive-option-in-argo-workflowsh2-br-">#</a></h2>
<p>The ability to store past workflow runs provides you with an accurate record of your past workflow states. This blueprint is a game changer, as it makes it possible to provision your task sets based on real-time metrics, such as spikes in processing needs from past deployments.</p>
<p>The workflow archive option stores your workflow states in either MySQL or Postgres. Once you have archives configured, you can use them to better understand how your jobs run and where you might be able to improve.</p>
<p>For example, they can help you know when it&rsquo;s a good idea to scale your traffic with the help of temporary instances, which will also have their states stored on the same database. With all your states held over time, you can apply rules to adjust your cluster size based on previous usage; a good time series analysis could even save you some money in the end.</p>
<p><img loading="lazy" src="https://user-images.githubusercontent.com/78096758/217069095-b10d7ff5-01f1-4213-98c4-02a35869a736.png" alt="postgres archiving"  />
</p>
<br />
The archive stores only the previous workflow states, not their detailed instance logs. Another thing to keep in mind is detailed audit logs. The artifact store option handles the detailed logs persistent option, storing it locally by [MinIO](https://min.io/). But you can also configure any other object storage option. This is covered in the [Argo official documetation](https://argoproj.github.io/argo-workflows/configure-artifact-repository/), where you can see how to use options such as [Google Cloud Storage](https://cloud.google.com/storage) buckets or [AWS S3](https://aws.amazon.com/s3/). 
<p>But before we start on the technical implementation, let&rsquo;s have a quick refresher on the components of Argo Workflows. It&rsquo;s necessary to know how they correlate with the persistent storage for your archived workflows; this image from the Argo Workflows documentation presents an overview of the environment where a workflow resides:</p>
<p><img loading="lazy" src="https://user-images.githubusercontent.com/78096758/217069401-e63ad934-46ae-4561-91ca-262089dd0131.png" alt="Argo Workflow Diagram"  />

<em>Source: Argo Workflow Github repository</em></p>
<h2 id="h2how-to-deploy-argo-workflows-with-persistent-storageh2br-"><h2>How to Deploy Argo Workflows with Persistent Storage</h2><br /><a hidden class="anchor" aria-hidden="true" href="#h2how-to-deploy-argo-workflows-with-persistent-storageh2br-">#</a></h2>
<p>Now that we know what&rsquo;s in store for us let&rsquo;s get started. We&rsquo;ll be using k3d to manage our local Kubernetes environment (instead of minikube and VirtualBox). In addition to k3d, you&rsquo;ll need to install Docker as an additional dependency. Using kubectl to interact with your Kubernetes cluster works fine, too. As for our tutorial, we&rsquo;ll be using local Kubernetes deployment scripts.</p>
<p>First, we&rsquo;ll start our local control plane with the following command:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">k3d cluster create cluster-demo 
</span></span></code></pre></div><p>The successful creation will provide a log similar to this one:</p>
<p><img loading="lazy" src="https://user-images.githubusercontent.com/78096758/217070632-b181c8a9-f684-4cf5-a58a-9b50d79d18a6.png" alt="Archive Info"  />

<em>Creating the cluster</em></p>
<br/>
Once we have our `cluster-demo`, we'll deploy our Argo Workflows instance. To install Argo Workflows, you'll need to execute the following commands:
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">kubectl create ns argo
</span></span><span class="line"><span class="cl">kubectl apply -n argo -f https://raw.githubusercontent.com/argoproj/argo-workflows/master/manifests/quick-start-postgres.yaml 
</span></span></code></pre></div><p>The first one creates a namespace called argo in your cluster, and the following line will deploy the Argo Workflows components on your cluster, as you can see below:</p>
<p><img loading="lazy" src="https://user-images.githubusercontent.com/78096758/217072204-32b27544-798d-489a-8e67-02994c386620.png" alt="postgres archiving"  />

<em>Deployments made on the cluster</em></p>
<h2 id="h2creating-the-workflow-controller-h2br-"><h2>Creating the workflow-controller </h2><br /><a hidden class="anchor" aria-hidden="true" href="#h2creating-the-workflow-controller-h2br-">#</a></h2>
<p>To run the workflow with the archive option, you must first change the persistence configuration to <code>archive:true</code> on your Argo server deployment. Changing it will tell your Argo server to store your workflow execution states into the database reported by the key <code>postgresql</code>.</p>
<p>We&rsquo;ll apply a new <code>ConfigMap</code> into our current Kubernetes argo namespace with the Postgres instance to store your archived workflows. You can then archive your workflows by using the <code>archiveLogs</code> option.</p>
<p>We had a Postgres instance deployed with the Quickstart YAML we used earlier. You&rsquo;ll need it only to apply the following configuration to your deployment. Changing this configuration enables your Argo server deployment to accept the <code>archiveLocation.archiveLogs</code> notation while creating your workflows. We&rsquo;ll start by creating a new <code>workflow-controller-configmap.yml</code> with the following content and saving it locally:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">apiVersion: v1
</span></span><span class="line"><span class="cl">kind: ConfigMap
</span></span><span class="line"><span class="cl">metadata:
</span></span><span class="line"><span class="cl">  name: workflow-controller-configmap
</span></span><span class="line"><span class="cl">data:
</span></span><span class="line"><span class="cl">  persistence: <span class="p">|</span>
</span></span><span class="line"><span class="cl">    connectionPool:
</span></span><span class="line"><span class="cl">      maxIdleConns: <span class="m">100</span>
</span></span><span class="line"><span class="cl">      maxOpenConns: <span class="m">0</span>
</span></span><span class="line"><span class="cl">      connMaxLifetime: 0s
</span></span><span class="line"><span class="cl">    nodeStatusOffLoad: <span class="nb">true</span>
</span></span><span class="line"><span class="cl">    archive: <span class="nb">true</span>
</span></span><span class="line"><span class="cl">    archiveTTL: 7d
</span></span><span class="line"><span class="cl">    postgresql:
</span></span><span class="line"><span class="cl">      host: postgres
</span></span><span class="line"><span class="cl">      port: <span class="m">5432</span>
</span></span><span class="line"><span class="cl">      database: postgres
</span></span><span class="line"><span class="cl">      tableName: argo_workflows
</span></span><span class="line"><span class="cl">      userNameSecret:
</span></span><span class="line"><span class="cl">        name: argo-postgres-config
</span></span><span class="line"><span class="cl">        key: username
</span></span><span class="line"><span class="cl">      passwordSecret:
</span></span><span class="line"><span class="cl">        name: argo-postgres-config
</span></span><span class="line"><span class="cl">        key: password
</span></span><span class="line"><span class="cl">  retentionPolicy: <span class="p">|</span>
</span></span><span class="line"><span class="cl">    completed: <span class="m">10</span>
</span></span><span class="line"><span class="cl">    failed: <span class="m">3</span>
</span></span><span class="line"><span class="cl">    errored: <span class="m">3</span> 
</span></span></code></pre></div><p>Deploy Your Environment with kubectl
We&rsquo;ll expose the Argo Workflows web UI using a load balancer on our argo namespace. The load balancer will expose the pod executing the web-facing component to connections made from outside Kubernetes.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">kubectl apply -n argo -f workflow-controller-configmap.yml 
</span></span></code></pre></div><p>Your Argo server will restart with the new configuration in a couple of minutes. Feel free to check its status by running <code>kubectl get -n argo svc,pod</code> on your Kubernetes cluster.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">kubectl get -n argo svc,pod 
</span></span></code></pre></div><p>You can then bind your Kubernetes cluster and your host to port 2746 by running the following on your cluster:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">kubectl -n argo port-forward deployment/argo-server 2746:2746 <span class="p">&amp;</span> 
</span></span></code></pre></div><p>Congratulations, you just deployed Argo Workflows on a k3d cluster. To confirm that your local instance is up and running, go to <code>https://localhost:2746</code>.</p>
<p><img loading="lazy" src="https://user-images.githubusercontent.com/78096758/217072659-01210f43-c734-49d3-8282-0dfbc8b5c49f.png" alt="Argo Workflow User info UI"  />

<em>Argo Workflows user info UI page</em>
<br /></p>
<h2 id="h2testing-your-deploymenth2br-"><h2>Testing Your Deployment</h2><br /><a hidden class="anchor" aria-hidden="true" href="#h2testing-your-deploymenth2br-">#</a></h2>
<p>Congratulations on installing your Argo Workflows instance on your local Kubernetes cluster with the archive option. And now that we have checked that off our list, let’s archive our workflows. Adding the <code>archiveLogs</code> annotation lets you specify which ones you want to archive, as demonstrated in the following template, which we&rsquo;ll call <code>workflow-archive.yml</code>.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">apiVersion: argoproj.io/v1alpha1
</span></span><span class="line"><span class="cl">kind: Workflow
</span></span><span class="line"><span class="cl">metadata:
</span></span><span class="line"><span class="cl">  generateName: archive-location-
</span></span><span class="line"><span class="cl">spec:
</span></span><span class="line"><span class="cl">  archiveLogs: <span class="nb">true</span> <span class="c1"># enables logs for this workflow</span>
</span></span><span class="line"><span class="cl">  entrypoint: whalesay
</span></span><span class="line"><span class="cl">  templates:
</span></span><span class="line"><span class="cl">  - name: whalesay
</span></span><span class="line"><span class="cl">    container:
</span></span><span class="line"><span class="cl">      image: docker/whalesay:latest
</span></span><span class="line"><span class="cl">      command: <span class="o">[</span>cowsay<span class="o">]</span>
</span></span><span class="line"><span class="cl">      args: <span class="o">[</span><span class="s2">&#34;hello world&#34;</span><span class="o">]</span> 
</span></span></code></pre></div><p>We need to execute <code>argo submit -n argo --watch -f workflow-archive.yml</code> on a terminal to deploy it.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">argo submit -n argo --watch -f workflow-archive.yml 
</span></span></code></pre></div><p>By doing so, you&rsquo;ll start the <code>archive-location</code> workflow under the <code>argo</code> namespace; the following output confirms that our example ran successfully:</p>
<p><img loading="lazy" src="https://user-images.githubusercontent.com/78096758/217072867-ae971ca3-0776-462a-8b8b-1209498873d6.png" alt="Argo Workflow Archive example"  />

<em>Argo Workflows archive example run output log</em> <br /></p>
<p>It doesn&rsquo;t change on the command line; however, as we have persistent storage for our workflows, you can see their previous states on the console UI. That&rsquo;ll give you the previous workflow states that ran with the archive options enabled—and going to the Argo Workflows console UI at <code>https://localhost:2746</code>, as we saw before, you can access the archived workflow UI option from the left menu bar’s icons. Once you are there, you can see all the past executions of a workflow. Your workflow history can be found in the UI under “Archived Workflows” (see below).</p>
<p><img loading="lazy" src="https://user-images.githubusercontent.com/78096758/217073174-b3762346-615e-4b90-8752-b2521acf769d.png" alt="Argo Workflow Archive Workflow Console"  />

<em>Argo Workflows archived workflow console</em>
<br />
<br /></p>
<h2 id="h2security-best-practices-for-archiving-argo-workflows-in-postgresh2br-"><h2>Security Best Practices for Archiving Argo Workflows in Postgres</h2><br /><a hidden class="anchor" aria-hidden="true" href="#h2security-best-practices-for-archiving-argo-workflows-in-postgresh2br-">#</a></h2>
<p>In our work, we deployed an Argo instance with the archive option configured with a Postgres database. As mentioned previously, this code isn&rsquo;t production-ready. As a next step, I suggest managing your access tokens to secure your Argo instance.</p>
<p>A good practice is to avoid hardcoded values for server runtime information when possible. Your infrastructure should generate data like your Postgres hostname on runtime instead of having it hardcoded. Your infrastructure should use secrets to store sensitive information like repository access keys.</p>
<p><img loading="lazy" src="https://user-images.githubusercontent.com/78096758/217073499-91ffe20f-6625-42ff-9688-b1b436fa6f1f.png" alt="postgres archiving"  />

<em>Postgres Archiving</em></p>
<p>Take a look at this <a href="https://opensource.com/article/19/6/introduction-kubernetes-secrets-and-configmaps">introduction about Secrets and configmaps in Kubernetes</a>, for more details on what Kubernetes information should be discreet. Adopting security best practices like this in the early stages is easier for both your users and developers as you start to scale. In addition, having your configuration automated ends up narrowing the <a href="https://csrc.nist.gov/glossary/term/attack_surface">attack surface</a> of your environment while also reducing infrastructure management tasks.</p>
<p>Here’s a <a href="https://blog.argoproj.io/practical-argo-workflows-hardening-dd8429acc1ce">helpful blog post</a> with more Argo security best practices from the Argo Workflows maintainer, Alex Collins.</p>
<h2 id="h2conclusionh2br-"><h2>Conclusion</h2><br /><a hidden class="anchor" aria-hidden="true" href="#h2conclusionh2br-">#</a></h2>
<p>We deployed Argo Workflows locally and archived a workflow using a Postgres database in this post. The scripts here are good starting points to understand and experiment with the archive option of Argo Workflows, but keep in mind that some critical factors are missing for a fully cloud native environment.</p>
<p>See you guys next time!</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://www.dawrlog.com/tags/kubernetes/">Kubernetes</a></li>
      <li><a href="https://www.dawrlog.com/tags/argo/">Argo</a></li>
      <li><a href="https://www.dawrlog.com/tags/development/">Development</a></li>
      <li><a href="https://www.dawrlog.com/tags/data-warehouse/">Data Warehouse</a></li>
      <li><a href="https://www.dawrlog.com/tags/best-practices/">Best Practices</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="https://www.dawrlog.com/posts/4/">
    <span class="title">« Prev</span>
    <br>
    <span>Ways to Debug an Argo Workflow.</span>
  </a>
  <a class="next" href="https://www.dawrlog.com/posts/3/">
    <span class="title">Next »</span>
    <br>
    <span>How to Mitigate DDoS Attacks on Your APIs.</span>
  </a>
</nav>


<div class="share-buttons">
    <a target="_blank" rel="noopener noreferrer" aria-label="share Archiving Argo Workflows: Postgres Database Setup on twitter"
        href="https://twitter.com/intent/tweet/?text=Archiving%20Argo%20Workflows%3a%20Postgres%20Database%20Setup&amp;url=https%3a%2f%2fwww.dawrlog.com%2fposts%2f2%2f&amp;hashtags=Kubernetes%2cArgo%2cDevelopment%2cDataWarehouse%2cBestPractices">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-253.927,424.544c135.939,0 210.268,-112.643 210.268,-210.268c0,-3.218 0,-6.437 -0.153,-9.502c14.406,-10.421 26.973,-23.448 36.935,-38.314c-13.18,5.824 -27.433,9.809 -42.452,11.648c15.326,-9.196 26.973,-23.602 32.49,-40.92c-14.252,8.429 -30.038,14.56 -46.896,17.931c-13.487,-14.406 -32.644,-23.295 -53.946,-23.295c-40.767,0 -73.87,33.104 -73.87,73.87c0,5.824 0.613,11.494 1.992,16.858c-61.456,-3.065 -115.862,-32.49 -152.337,-77.241c-6.284,10.881 -9.962,23.601 -9.962,37.088c0,25.594 13.027,48.276 32.95,61.456c-12.107,-0.307 -23.448,-3.678 -33.41,-9.196l0,0.92c0,35.862 25.441,65.594 59.311,72.49c-6.13,1.686 -12.72,2.606 -19.464,2.606c-4.751,0 -9.348,-0.46 -13.946,-1.38c9.349,29.426 36.628,50.728 68.965,51.341c-25.287,19.771 -57.164,31.571 -91.8,31.571c-5.977,0 -11.801,-0.306 -17.625,-1.073c32.337,21.15 71.264,33.41 112.95,33.41Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Archiving Argo Workflows: Postgres Database Setup on linkedin"
        href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fwww.dawrlog.com%2fposts%2f2%2f&amp;title=Archiving%20Argo%20Workflows%3a%20Postgres%20Database%20Setup&amp;summary=Archiving%20Argo%20Workflows%3a%20Postgres%20Database%20Setup&amp;source=https%3a%2f%2fwww.dawrlog.com%2fposts%2f2%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Archiving Argo Workflows: Postgres Database Setup on reddit"
        href="https://reddit.com/submit?url=https%3a%2f%2fwww.dawrlog.com%2fposts%2f2%2f&title=Archiving%20Argo%20Workflows%3a%20Postgres%20Database%20Setup">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Archiving Argo Workflows: Postgres Database Setup on facebook"
        href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fwww.dawrlog.com%2fposts%2f2%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Archiving Argo Workflows: Postgres Database Setup on whatsapp"
        href="https://api.whatsapp.com/send?text=Archiving%20Argo%20Workflows%3a%20Postgres%20Database%20Setup%20-%20https%3a%2f%2fwww.dawrlog.com%2fposts%2f2%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Archiving Argo Workflows: Postgres Database Setup on telegram"
        href="https://telegram.me/share/url?text=Archiving%20Argo%20Workflows%3a%20Postgres%20Database%20Setup&amp;url=https%3a%2f%2fwww.dawrlog.com%2fposts%2f2%2f">
        <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
            <path
                d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
        </svg>
    </a>
</div>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2023 <a href="https://www.dawrlog.com/">Dataware Logistics</a>; <br /> created with 🧡 on 🐧 machines running ☸️ pods.</span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a><script src='https://storage.ko-fi.com/cdn/scripts/overlay-widget.js'></script>
<script>
  kofiWidgetOverlay.draw('dawrlog', {
    'type': 'floating-chat',
    'floating-chat.donateButton.text': 'Tip jar',
    'floating-chat.donateButton.background-color': '#794bc4',
    'floating-chat.donateButton.text-color': '#fff'
  });
</script>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
