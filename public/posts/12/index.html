<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>How to Value Stream DataOps? | Dataware Logistics</title>
<meta name="keywords" content="DataOps, Lean Agile, Best Practices">
<meta name="description" content="Hello everyone, today we will check how to properly value stream your DataOps initiative.
Enhancements on data ingestion made evident the amount of data lost when generating insights. However, without guidance from methodologies like The DataOps Manifesto, some companies are still struggling to blend data pipelines from legacy databases, such as an ADABAS database, with new ones, such as MongoDB or Neo4j.
And it‚Äôs always good to point out that these legacy systems aren‚Äôt easy to let go of.">
<meta name="author" content="Daniel Paes">
<link rel="canonical" href="https://www.enov8.com/blog/how-to-value-stream-dataops-2/">
<meta name="google-site-verification" content="4599922566">
<link crossorigin="anonymous" href="/assets/css/stylesheet.css" rel="preload stylesheet" as="style">
<link rel="icon" href="https://www.dawrlog.com/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://www.dawrlog.com/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://www.dawrlog.com/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://www.dawrlog.com/apple-touch-icon.png">
<link rel="mask-icon" href="https://www.dawrlog.com/apple-touch-icon.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://www.dawrlog.com/posts/12/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="How to Value Stream DataOps?" />
<meta property="og:description" content="Hello everyone, today we will check how to properly value stream your DataOps initiative.
Enhancements on data ingestion made evident the amount of data lost when generating insights. However, without guidance from methodologies like The DataOps Manifesto, some companies are still struggling to blend data pipelines from legacy databases, such as an ADABAS database, with new ones, such as MongoDB or Neo4j.
And it‚Äôs always good to point out that these legacy systems aren‚Äôt easy to let go of." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://www.dawrlog.com/posts/12/" />
<meta property="og:image" content="https://user-images.githubusercontent.com/78096758/217092056-02f22c71-de93-4223-88c0-fc60f8f662b1.png" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-11-24T00:00:00+00:00" />
<meta property="article:modified_time" content="2021-11-24T00:00:00+00:00" />

<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="https://user-images.githubusercontent.com/78096758/217092056-02f22c71-de93-4223-88c0-fc60f8f662b1.png" />
<meta name="twitter:title" content="How to Value Stream DataOps?"/>
<meta name="twitter:description" content="Hello everyone, today we will check how to properly value stream your DataOps initiative.
Enhancements on data ingestion made evident the amount of data lost when generating insights. However, without guidance from methodologies like The DataOps Manifesto, some companies are still struggling to blend data pipelines from legacy databases, such as an ADABAS database, with new ones, such as MongoDB or Neo4j.
And it‚Äôs always good to point out that these legacy systems aren‚Äôt easy to let go of."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://www.dawrlog.com/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "How to Value Stream DataOps?",
      "item": "https://www.dawrlog.com/posts/12/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "How to Value Stream DataOps?",
  "name": "How to Value Stream DataOps?",
  "description": "Hello everyone, today we will check how to properly value stream your DataOps initiative.\nEnhancements on data ingestion made evident the amount of data lost when generating insights. However, without guidance from methodologies like The DataOps Manifesto, some companies are still struggling to blend data pipelines from legacy databases, such as an ADABAS database, with new ones, such as MongoDB or Neo4j.\nAnd it‚Äôs always good to point out that these legacy systems aren‚Äôt easy to let go of.",
  "keywords": [
    "DataOps", "Lean Agile", "Best Practices"
  ],
  "articleBody": "Hello everyone, today we will check how to properly value stream your DataOps initiative.\nEnhancements on data ingestion made evident the amount of data lost when generating insights. However, without guidance from methodologies like The DataOps Manifesto, some companies are still struggling to blend data pipelines from legacy databases, such as an ADABAS database, with new ones, such as MongoDB or Neo4j.\nAnd it‚Äôs always good to point out that these legacy systems aren‚Äôt easy to let go of. Most of them are responsible for core processing (like the bank transactions in Cobol, for example). As such, it‚Äôs not attractive to change them because it‚Äôs too problematic.\nWith that said, I believe the integration of new applications and legacy databases is one of the biggest challenges for data-driven companies. However, there have been significant advancements in the methodologies and frameworks for data ingestion over the last few years. Why Is It So Essential to Have Precise Data? With optimized data ingestion pipelines, you can become better at decision-making. At the same time, updating your subject-focused legacy systems into modular applications sounds promising, right?\nThe good news is, doing so isn‚Äôt a far-fetched dream! Thanks to advancements around computing power, it‚Äôs now possible to do way more with very little. We can now deconstruct bloated applications into slimmer versions.\nUsing concepts that used to be possible only in theory, we can now ingest data from unusual places. For example, we can have an automated pipeline to ingest data from digitized documents thanks to Optical Character Recognition, or OCR. How cool is that?\nIn this post, I want to help you understand how your organization will benefit from a mature DataOps environment. First, I‚Äôll present what DataOps is and why it‚Äôs not only DevOps for data. Then, I‚Äôll explain some significant benefits that come from mapping the value streams for your own DataOps practice. Last, I‚Äôll present some considerations when applying the DataOps framework to your team. What Is DataOps? It‚Äôs hard to provide your users with the most accurate metrics for existing dashboards with multiple data suppliers. It gets worse when your legacy database has so much technical debt that carrying out something as simple as creating a Key Process Indicator, or KPI, is an absolute nightmare.\nAnd here‚Äôs where DataOps comes to the rescue! It makes it possible for your users to consume your data faster and in an automated environment integrated with the most updated version of your data suppliers. Pretty neat, right?\nI like to remember that this isn‚Äôt something new, as the decision support system (DSS) consists of an automated environment for your analytics pipelines. And I believe that DSSs always played an essential part in any company. The benefits for stakeholders include getting a complete understanding of your supply chain process or knowing faster which department or product is more profitable, to list a few.\nThe data suppliers load these systems, which can be any source of information for your needs. Some examples of information provided by data suppliers include\nHuman resources data Agency campaign data Supply chain IoT devices Billing systems Server and traffic logs DataOps vs. Decision Support Systems. You often see orchestrated data pipelines from different data suppliers in legacy DSSs. So, each data supplier loads its data into this centralized database. But these independent data flows cause inconsistent data, making it hard to trust the DSS‚Äôs presented results.\nWhat DataOps facilitates is better results with an optimized DSS! Thanks to the agile approach, DataOps reinforces a more customer-centric approach when compared to DSS because of its modular architecture. In addition, DataOps eases constraints on scalability, automation, and security thanks to the reuse of components used by other data pipelines.\nThese components can vary from simple database connectivity to a business rule used by the finance department that human resources could benefit from. All of this is thanks to repositories that are centralized, standardized, and reusable. Where DataOps Intersects and Where It Strays From DevOps\nWhile DataOps seems like DevOps for data, I like to remember that the goals of DevOps and DataOps are different, although the methodologies share the same principles.\nDevOps focuses on loosening development to include operations. On the other hand, the goal of DataOps is to make analytics development more functional. DataOps uses statistical process control, the mathematical approach used in lean manufacturing, DevOps disciplines, and best practices from the Agile Manifesto.\nWith these strategies in place, you can decouple your environment; DataOps makes it easier to detach your business logic and technical constraints from your data pipelines. As a result, you‚Äôre more confident in your data while enabling your teams to react better to data trends.\nYou‚Äôll benefit from the efficiency and results faster while designing your data pipeline components. And your teams will be more focused on delivering value rather than being tied down by technical decisions made in the past.\nAlso, I always like to bring up the security gains resulting from proper deployment of DataOps: robust, secure systems that are less prone to breaches and leaks! Benefits to Consider While Mapping Your Value Streams\nNow that we know what DataOps is about, I want to present the benefits of correctly mapping your value streams.\nMy focus here is the benefits for your data pipelines, although they can also apply to your application deployments. From the business perspective, the principal value added by DataOps adoption is the ability to explore new data sources rapidly.\nHere are the advantages of the value added to the customer when mapping your value streams. Enhanced Control Thanks to Technical Decoupling.\nAs I mentioned before, data suppliers are any source applications with relevant data for your analysis. In other words, they‚Äôre data entry points that feed your data pipeline.\nThese applications produce data in a raw state. And as the name implies, this data should be left as untouched as possible. It‚Äôs beneficial in cases of reprocessing or data lineage analysis.\nThis data needs additional processing steps to remove unnecessary noise from it, as its original form might not be a good fit for your needs. However, from this output, you can extract the necessary metrics to cover the needs of your users.\nI also want to bring up one of the values from conscious decoupling: its robust automated control of each component‚Äôs data pipeline. This orchestration brings up extra quality measures, making it possible to increase productivity given that your users won‚Äôt need to perform repetitive tasks. Fast Exploration of Existing and New Data Suppliers.\nOn legacy systems, the development of new pipelines is chaotic, as previously mentioned. The DataOps approach also enables fast exploration of your data suppliers.\nDataOps makes it easier to create conformed components thanks to its modular deployment. What I mean by that is that you can reuse already deployed and tested components.\nIn other words, DataOps enables a mindset of continuous improvement. Therefore, it will drastically lower your development costs and increase your return on investment at the same time.\nYour team will handle more challenging tasks on bringing business value, not with daily data wrangling activities. As a result, you get an instant productivity boost thanks to the automated deployment of your application. Reliable Data Governance.\nAs a result of the automated data pipelines deployed by DataOps, it becomes easier to trace how your users consume your data. This information can help you quickly answer recurring questions.\nYour users can see where the business logic is in a blink of an eye. Moreover, the reference between its canonical and technical implementation name becomes easy to absorb since new analysts getting onboarded to your projects makes it an appealing source for your data profiling.\nAs a result, a solid datalog of your data suppliers is a mandatory step to think about when mapping your value streams, in my opinion. It becomes easy to manage your data pipelines when you create an enterprise-level conformed business catalogue. All this structured information about your data suppliers creates an intuitive data catalogue.\nThis information, also known as metadata, provides the business context where this data gives its value. So, in other words, your insights would become more accurate. Important Considerations About Your Own DataOps Deployment.\nWhat we‚Äôve seen so far shows how conformed detached modules enable a more robust data catalogue for your company. In addition, the coherence among your analytics components clarifies where you can enhance your data ingestion.\nI always like to remember that these improvements don‚Äôt come for free. As you‚Äôll react faster and more wisely, be ready to reshape some of your company‚Äôs internal processes. Bear in mind that it‚Äôs hard to teach an old dog new tricks. So, expect some resistance from more experienced teammates.\nA self-healing data pipeline scales horizontally or vertically when needed. So, you can add more units for processing power (known as horizontal scaling) or enhance your clusters (known as vertical scaling) when your sets start to have some bottleneck issues while processing your data; Remember the rule of thumb:\nIt gets easier to enrich your outputs when you‚Äôre fully aware of your data scope. So, in addition to its modular components, DataOps enables actions like masking and obfuscating your data to occur more fluidly in the early stages of its processing.\nWith DataOps, you‚Äôre building up a trustworthy data pipeline capable of reacting to new concepts and technologies at the same speed as your business‚Äôs evolution. Final Thoughts.\nIn this post, I gave an overview of what you‚Äôll gain by correctly deploying DataOps. The result is a mix of business and technical added value because you‚Äôll have slim and robust orchestrated data pipelines.\nI started by presenting what DataOps is and what business value it brings. Then, I explained where it intersects and where its goals differ from agile and DevOps methodologies.\nWe also took a quick look at what I believe to be the short-term benefits from the correct deployment of a mature DataOps implementation and how automated deployments can add technical value.\nLast, we saw some challenges that your team may face when you adopt DataOps. For example, your unit may be resistant to adopting new technologies and methodologies. However, we also saw the benefits of a correct deployment as a concise data catalogue.\nJust remember that you must completely implement DataOps‚Äôs requirements. So, don‚Äôt expect to have a reliable DataOps implementation with partial deployments of agile or DevOps disciplines.\nFor further help transforming your data, you can reach out to us with any questions you have and even discover new info you weren‚Äôt aware of with a better insight from better understanding your data.\nSee you next time!\n",
  "wordCount" : "1772",
  "inLanguage": "en",
  "image":"https://user-images.githubusercontent.com/78096758/217092056-02f22c71-de93-4223-88c0-fc60f8f662b1.png","datePublished": "2021-11-24T00:00:00Z",
  "dateModified": "2021-11-24T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Daniel Paes"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://www.dawrlog.com/posts/12/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Dataware Logistics",
    "logo": {
      "@type": "ImageObject",
      "url": "https://www.dawrlog.com/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://www.dawrlog.com/" accesskey="h" title="Dataware Logistics (Alt + H)">Dataware Logistics</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
                <ul class="lang-switch"><li>|</li>
                    <li>
                        <a href="https://www.dawrlog.com/fr/" title="French"
                            aria-label=":fr:">üá´üá∑</a>
                    </li>
                </ul>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://www.dawrlog.com/about" title="About">
                    <span>About</span>
                </a>
            </li>
            <li>
                <a href="https://www.dawrlog.com/posts/" title="Posts">
                    <span>Posts</span>
                </a>
            </li>
            <li>
                <a href="https://calendly.com/dawrlog" title="Contact">
                    <span>Contact</span>&nbsp;
                    <svg fill="none" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round"
                        stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12">
                        <path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"></path>
                        <path d="M15 3h6v6"></path>
                        <path d="M10 14L21 3"></path>
                    </svg>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://www.dawrlog.com/">Home</a>&nbsp;¬ª&nbsp;<a href="https://www.dawrlog.com/posts/">Posts</a></div>
    <h1 class="post-title">
      How to Value Stream DataOps?
    </h1>
    <div class="post-meta"><span title='2021-11-24 00:00:00 +0000 UTC'>November 24, 2021</span>&nbsp;¬∑&nbsp;9 min&nbsp;¬∑&nbsp;Daniel Paes

</div>
  </header> 
<figure class="entry-cover"><img loading="lazy" src="https://user-images.githubusercontent.com/78096758/217092056-02f22c71-de93-4223-88c0-fc60f8f662b1.png" alt="">
        
</figure><div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><nav id="TableOfContents">
  <ul>
    <li><a href="#h2-why-is-it-so-essential-to-have-precise-data-h2br-"><h2> Why Is It So Essential to Have Precise Data? </h2><br /></a></li>
    <li><a href="#h2-what-is-dataops-h2br-"><h2> What Is DataOps? </h2><br /></a></li>
    <li><a href="#h2-dataops-vs-decision-support-systems-h2br-"><h2> DataOps vs. Decision Support Systems. </h2><br /></a></li>
    <li><a href="#h2-where-dataops-intersects-and-where-it-strays-from-devopsh2br-"><h2> Where DataOps Intersects and Where It Strays From DevOps</h2><br /></a></li>
    <li><a href="#h2benefits-to-consider-while-mapping-your-value-streamsh2br-"><h2>Benefits to Consider While Mapping Your Value Streams</h2><br /></a></li>
    <li><a href="#h3enhanced-control-thanks-to-technical-decouplingh3br-"><h3>Enhanced Control Thanks to Technical Decoupling.</h3><br /></a></li>
    <li><a href="#h3fast-exploration-of-existing-and-new-data-suppliersh3br-"><h3>Fast Exploration of Existing and New Data Suppliers.</h3><br /></a></li>
    <li><a href="#h3reliable-data-governanceh3br-"><h3>Reliable Data Governance.</h3><br /></a></li>
    <li><a href="#h2important-considerations-about-your-own-dataops-deploymenth2br-"><h2>Important Considerations About Your Own DataOps Deployment.</h2><br /></a></li>
    <li><a href="#h2final-thoughtsh2br-"><h2>Final Thoughts.</h2><br /></a></li>
  </ul>
</nav>
        </div>
    </details>
</div>

  <div class="post-content"><p>Hello everyone, today we will check how to properly value stream your DataOps initiative.</p>
<p>Enhancements on data ingestion made evident the amount of data lost when generating insights. However, without guidance from methodologies like <a href="https://www.dataopsmanifesto.org/">The DataOps Manifesto</a>, some companies are still struggling to blend data pipelines from legacy databases, such as an ADABAS database, with new ones, such as MongoDB or Neo4j.</p>
<p>And it‚Äôs always good to point out that these legacy systems aren‚Äôt easy to let go of. Most of them are responsible for core processing (like the bank transactions in Cobol, for example). As such, it‚Äôs not attractive to change them because it‚Äôs too problematic.</p>
<p>With that said, I believe the integration of new applications and legacy databases is one of the <a href="https://www.docshifter.com/blog/what-to-do-with-legacy-data/">biggest challenges</a> for data-driven companies. However, there have been significant advancements in the methodologies and frameworks for data ingestion over the last few years.
<br /><br /></p>
<h2 id="h2-why-is-it-so-essential-to-have-precise-data-h2br-"><h2> Why Is It So Essential to Have Precise Data? </h2><br /><a hidden class="anchor" aria-hidden="true" href="#h2-why-is-it-so-essential-to-have-precise-data-h2br-">#</a></h2>
<p>With optimized data ingestion pipelines, you can become better at decision-making. At the same time, updating your subject-focused legacy systems into modular applications sounds promising, right?</p>
<p>The good news is, doing so isn‚Äôt a far-fetched dream! Thanks to advancements around computing power, it‚Äôs now possible to do way more with very little. We can now deconstruct bloated applications into slimmer versions.</p>
<p>Using concepts that used to be possible only in theory, we can now ingest data from unusual places. For example, we can have an automated pipeline to ingest data from digitized documents thanks to <a href="https://en.wikipedia.org/wiki/Optical_character_recognition">Optical Character Recognition</a>, or OCR. How cool is that?</p>
<p>In this post, I want to help you understand how your organization will benefit from a mature DataOps environment. First, I‚Äôll present what DataOps is and why it‚Äôs not only DevOps for data. Then, I‚Äôll explain some significant benefits that come from mapping the value streams for your own DataOps practice. Last, I‚Äôll present some considerations when applying the DataOps framework to your team.
<br /><br /></p>
<h2 id="h2-what-is-dataops-h2br-"><h2> What Is DataOps? </h2><br /><a hidden class="anchor" aria-hidden="true" href="#h2-what-is-dataops-h2br-">#</a></h2>
<p>It‚Äôs hard to provide your users with the most accurate metrics for existing dashboards with multiple data suppliers. It gets worse when your legacy database has so much technical debt that carrying out something as simple as creating a <a href="https://kpi.org/KPI-Basics">Key Process Indicator</a>, or KPI, is an absolute nightmare.</p>
<p>And here‚Äôs where DataOps comes to the rescue! It makes it possible for your users to consume your data faster and in an automated environment integrated with the most updated version of your data suppliers. Pretty neat, right?</p>
<p>I like to remember that this isn‚Äôt something new, as the <a href="https://www.investopedia.com/terms/d/decision-support-system.asp">decision support system</a> (DSS) consists of an automated environment for your analytics pipelines. And I believe that DSSs always played an essential part in any company. The benefits for stakeholders include getting a complete understanding of your supply chain process or knowing faster which department or product is more profitable, to list a few.</p>
<p>The data suppliers load these systems, which can be any source of information for your needs. Some examples of information provided by data suppliers include</p>
<ul>
<li>Human resources data</li>
<li>Agency campaign data</li>
<li>Supply chain IoT devices</li>
<li>Billing systems</li>
<li>Server and traffic logs
<br /><br /></li>
</ul>
<h2 id="h2-dataops-vs-decision-support-systems-h2br-"><h2> DataOps vs. Decision Support Systems. </h2><br /><a hidden class="anchor" aria-hidden="true" href="#h2-dataops-vs-decision-support-systems-h2br-">#</a></h2>
<p>You often see orchestrated data pipelines from different data suppliers in legacy DSSs. So, each data supplier loads its data into this centralized database. But these independent data flows cause inconsistent data, making it hard to trust the DSS‚Äôs presented results.</p>
<p>What DataOps facilitates is <strong>better results with an optimized DSS</strong>! Thanks to the agile approach, DataOps reinforces a more customer-centric approach when compared to DSS because of its modular architecture. In addition, DataOps eases constraints on scalability, automation, and security thanks to the reuse of components used by other data pipelines.</p>
<p>These components can vary from simple database connectivity to a business rule used by the finance department that human resources could benefit from. All of this is thanks to repositories that are centralized, standardized, and reusable.
<br /><br /></p>
<h2 id="h2-where-dataops-intersects-and-where-it-strays-from-devopsh2br-"><h2> Where DataOps Intersects and Where It Strays From DevOps</h2><br /><a hidden class="anchor" aria-hidden="true" href="#h2-where-dataops-intersects-and-where-it-strays-from-devopsh2br-">#</a></h2>
<p>While DataOps seems like DevOps for data, I like to remember that the goals of DevOps and DataOps are different, although the methodologies share the same principles.</p>
<p>DevOps focuses on loosening development to include operations. On the other hand, the goal of DataOps is to make analytics development more functional. DataOps uses <a href="https://en.wikipedia.org/wiki/Statistical_process_control">statistical process control</a>, the mathematical approach used in <a href="https://en.wikipedia.org/wiki/Lean_manufacturing">lean manufacturing</a>, DevOps disciplines, and best practices from the <a href="https://en.wikipedia.org/wiki/Agile_software_development#The_Manifesto_for_Agile_Software_Development">Agile Manifesto</a>.</p>
<p>With these strategies in place, you can decouple your environment; DataOps makes it easier to detach your business logic and technical constraints from your data pipelines. As a result, you‚Äôre more confident in your data while enabling your teams to react better to data trends.</p>
<p>You‚Äôll benefit from the efficiency and results faster while designing your data pipeline components. And your teams will be more focused on delivering value rather than being tied down by technical decisions made in the past.</p>
<p>Also, I always like to bring up the security gains resulting from proper deployment of DataOps: robust, secure systems that are less prone to breaches and leaks!
<br /><br /></p>
<h2 id="h2benefits-to-consider-while-mapping-your-value-streamsh2br-"><h2>Benefits to Consider While Mapping Your Value Streams</h2><br /><a hidden class="anchor" aria-hidden="true" href="#h2benefits-to-consider-while-mapping-your-value-streamsh2br-">#</a></h2>
<p>Now that we know what DataOps is about, I want to present the benefits of correctly mapping your <a href="https://www.atlassian.com/continuous-delivery/principles/value-stream-mapping">value streams</a>.</p>
<p>My focus here is the benefits for your data pipelines, although they can also apply to your application deployments. From the business perspective, the principal value added by DataOps adoption is the ability to explore new data sources rapidly.</p>
<p>Here are the advantages of the <a href="https://berteig.com/how-to-apply-agile/value-added-work-basic-lean-concepts/">value added</a> to the customer when mapping your value streams.
<br /><br /></p>
<h2 id="h3enhanced-control-thanks-to-technical-decouplingh3br-"><h3>Enhanced Control Thanks to Technical Decoupling.</h3><br /><a hidden class="anchor" aria-hidden="true" href="#h3enhanced-control-thanks-to-technical-decouplingh3br-">#</a></h2>
<p>As I mentioned before, data suppliers are any source applications with relevant data for your analysis. In other words, they‚Äôre data entry points that feed your data pipeline.</p>
<p>These applications produce data in a raw state. And as the name implies, this data should be left as untouched as possible. It‚Äôs beneficial in cases of reprocessing or data lineage analysis.</p>
<p>This data needs additional processing steps to remove unnecessary noise from it, as its original form might not be a good fit for your needs. However, from this output, you can extract the necessary metrics to cover the needs of your users.</p>
<p>I also want to bring up one of the values from conscious decoupling: its robust automated control of each component‚Äôs data pipeline. This orchestration brings up extra quality measures, making it possible to increase productivity given that your users won‚Äôt need to perform repetitive tasks.
<br /><br /></p>
<h2 id="h3fast-exploration-of-existing-and-new-data-suppliersh3br-"><h3>Fast Exploration of Existing and New Data Suppliers.</h3><br /><a hidden class="anchor" aria-hidden="true" href="#h3fast-exploration-of-existing-and-new-data-suppliersh3br-">#</a></h2>
<p>On legacy systems, the development of new pipelines is chaotic, as previously mentioned. The DataOps approach also enables fast exploration of your data suppliers.</p>
<p>DataOps makes it easier to create conformed components thanks to its modular deployment. What I mean by that is that you can reuse already deployed and tested components.</p>
<p>In other words, DataOps enables a mindset of continuous improvement. Therefore, it will drastically lower your development costs and increase your return on investment at the same time.</p>
<p>Your team will handle more challenging tasks on bringing business value, not with daily data wrangling activities. As a result, you get an instant productivity boost thanks to the automated deployment of your application.
<br /><br /></p>
<h2 id="h3reliable-data-governanceh3br-"><h3>Reliable Data Governance.</h3><br /><a hidden class="anchor" aria-hidden="true" href="#h3reliable-data-governanceh3br-">#</a></h2>
<p>As a result of the automated data pipelines deployed by DataOps, it becomes easier to trace how your users consume your data. This information can help you quickly answer recurring questions.</p>
<p>Your users can see where the business logic is in a blink of an eye. Moreover, the reference between its canonical and technical implementation name becomes easy to absorb since new analysts getting onboarded to your projects makes it an appealing source for your data profiling.</p>
<p>As a result, a solid datalog of your data suppliers is a mandatory step to think about when mapping your value streams, in my opinion. It becomes easy to manage your data pipelines when you create an enterprise-level conformed business catalogue. All this structured information about your data suppliers creates an intuitive data catalogue.</p>
<p>This information, also known as metadata, provides the business context where this data gives its value. So, in other words, your insights would become more accurate.
<br /><br /></p>
<h2 id="h2important-considerations-about-your-own-dataops-deploymenth2br-"><h2>Important Considerations About Your Own DataOps Deployment.</h2><br /><a hidden class="anchor" aria-hidden="true" href="#h2important-considerations-about-your-own-dataops-deploymenth2br-">#</a></h2>
<p>What we‚Äôve seen so far shows how conformed detached modules enable a more robust data catalogue for your company. In addition, the coherence among your analytics components clarifies where you can enhance your data ingestion.</p>
<p>I always like to remember that these improvements don‚Äôt come for free. As you‚Äôll react faster and more wisely, be ready to reshape some of your company‚Äôs internal processes. Bear in mind that it‚Äôs hard to teach an old dog new tricks. So, expect some resistance from more experienced teammates.</p>
<p>A self-healing data pipeline scales horizontally or vertically when needed. So, you can add more units for processing power (known as horizontal scaling) or enhance your clusters (known as vertical scaling) when your sets start to have some bottleneck issues while processing your data; <strong><em>Remember the rule of thumb</em></strong>:</p>
<blockquote>
<p>It gets easier to enrich your outputs when you‚Äôre fully aware of your data scope. So, in addition to its modular components, DataOps enables actions like masking and obfuscating your data to occur more fluidly in the early stages of its processing.</p>
</blockquote>
<p>With DataOps, you‚Äôre building up a <strong>trustworthy data pipeline</strong> capable of reacting to new concepts and technologies at the <strong><em>same speed</em></strong> as your <strong><em>business‚Äôs evolution</em></strong>.
<br /><br /></p>
<h2 id="h2final-thoughtsh2br-"><h2>Final Thoughts.</h2><br /><a hidden class="anchor" aria-hidden="true" href="#h2final-thoughtsh2br-">#</a></h2>
<p>In this post, I gave an overview of what you‚Äôll gain by correctly deploying DataOps. The result is a mix of business and technical added value because you‚Äôll have slim and robust orchestrated data pipelines.</p>
<p>I started by presenting what DataOps is and what business value it brings. Then, I explained where it intersects and where its goals differ from agile and DevOps methodologies.</p>
<p>We also took a quick look at what I believe to be the short-term benefits from the correct deployment of a mature DataOps implementation and how automated deployments can add technical value.</p>
<p>Last, we saw some challenges that your team may face when you adopt DataOps. For example, your unit may be <strong>resistant</strong> to <strong><em>adopting new technologies and methodologies</em></strong>. However, we also saw the benefits of a correct deployment as a <strong><em>concise data catalogue</em></strong>.</p>
<p>Just remember that you must completely implement DataOps‚Äôs requirements. So, don‚Äôt expect to have a reliable DataOps implementation with partial deployments of agile or DevOps disciplines.</p>
<p>For further help transforming your data, you can <a href="https://calendly.com/dawrlog">reach out to us</a> with any questions you have and even discover new info you weren&rsquo;t aware of with a better insight from better understanding your data.</p>
<p>See you next time!</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://www.dawrlog.com/tags/dataops/">DataOps</a></li>
      <li><a href="https://www.dawrlog.com/tags/lean-agile/">Lean Agile</a></li>
      <li><a href="https://www.dawrlog.com/tags/best-practices/">Best Practices</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="https://www.dawrlog.com/posts/10/">
    <span class="title">¬´ Prev</span>
    <br>
    <span>BigQuery Data Types Examined &amp; Explained</span>
  </a>
  <a class="next" href="https://www.dawrlog.com/posts/14/">
    <span class="title">Next ¬ª</span>
    <br>
    <span>What Is the Identity and Access Provisioning Lifecycle?</span>
  </a>
</nav>


<div class="share-buttons">
    <a target="_blank" rel="noopener noreferrer" aria-label="share How to Value Stream DataOps? on twitter"
        href="https://twitter.com/intent/tweet/?text=How%20to%20Value%20Stream%20DataOps%3f&amp;url=https%3a%2f%2fwww.dawrlog.com%2fposts%2f12%2f&amp;hashtags=DataOps%2cLeanAgile%2cBestPractices">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-253.927,424.544c135.939,0 210.268,-112.643 210.268,-210.268c0,-3.218 0,-6.437 -0.153,-9.502c14.406,-10.421 26.973,-23.448 36.935,-38.314c-13.18,5.824 -27.433,9.809 -42.452,11.648c15.326,-9.196 26.973,-23.602 32.49,-40.92c-14.252,8.429 -30.038,14.56 -46.896,17.931c-13.487,-14.406 -32.644,-23.295 -53.946,-23.295c-40.767,0 -73.87,33.104 -73.87,73.87c0,5.824 0.613,11.494 1.992,16.858c-61.456,-3.065 -115.862,-32.49 -152.337,-77.241c-6.284,10.881 -9.962,23.601 -9.962,37.088c0,25.594 13.027,48.276 32.95,61.456c-12.107,-0.307 -23.448,-3.678 -33.41,-9.196l0,0.92c0,35.862 25.441,65.594 59.311,72.49c-6.13,1.686 -12.72,2.606 -19.464,2.606c-4.751,0 -9.348,-0.46 -13.946,-1.38c9.349,29.426 36.628,50.728 68.965,51.341c-25.287,19.771 -57.164,31.571 -91.8,31.571c-5.977,0 -11.801,-0.306 -17.625,-1.073c32.337,21.15 71.264,33.41 112.95,33.41Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share How to Value Stream DataOps? on linkedin"
        href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fwww.dawrlog.com%2fposts%2f12%2f&amp;title=How%20to%20Value%20Stream%20DataOps%3f&amp;summary=How%20to%20Value%20Stream%20DataOps%3f&amp;source=https%3a%2f%2fwww.dawrlog.com%2fposts%2f12%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share How to Value Stream DataOps? on reddit"
        href="https://reddit.com/submit?url=https%3a%2f%2fwww.dawrlog.com%2fposts%2f12%2f&title=How%20to%20Value%20Stream%20DataOps%3f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share How to Value Stream DataOps? on facebook"
        href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fwww.dawrlog.com%2fposts%2f12%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share How to Value Stream DataOps? on whatsapp"
        href="https://api.whatsapp.com/send?text=How%20to%20Value%20Stream%20DataOps%3f%20-%20https%3a%2f%2fwww.dawrlog.com%2fposts%2f12%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share How to Value Stream DataOps? on telegram"
        href="https://telegram.me/share/url?text=How%20to%20Value%20Stream%20DataOps%3f&amp;url=https%3a%2f%2fwww.dawrlog.com%2fposts%2f12%2f">
        <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
            <path
                d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
        </svg>
    </a>
</div>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2023 <a href="https://www.dawrlog.com/">Dataware Logistics</a>; <br /> created with üß° on üêß machines running ‚ò∏Ô∏è pods.</span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a><script src='https://storage.ko-fi.com/cdn/scripts/overlay-widget.js'></script>
<script>
  kofiWidgetOverlay.draw('dawrlog', {
    'type': 'floating-chat',
    'floating-chat.donateButton.text': 'Tip jar',
    'floating-chat.donateButton.background-color': '#794bc4',
    'floating-chat.donateButton.text-color': '#fff'
  });
</script>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
