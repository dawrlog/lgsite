<!DOCTYPE html>
<html lang="fr" dir="fr">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Archivage des Argo Workflows dans une instance Postgres: Quoi a faire pour configurer votre entrepôt de données | Logistique Dataware</title>
<meta name="keywords" content="Kubernetes, Argo, Development, Data Warehouse, Best Practices">
<meta name="description" content="Bonjour à tous, j&rsquo;espère que vous allez bien !
Si vous connaissez Argo Workflows, vous savez déjà qu&rsquo;il peut piloter vos pipelines CI/CD, gérer vos processus ETL et orchestrer tout ensemble de tâches que vous pouvez imaginer pour un cluster Kubernetes. Mais saviez-vous qu&rsquo;Argo sait aussi archiver les résultats de ses workflows dans une base de données SQL ?
Dans ce billet, je vais montrer comment Argo Workflows archive l&rsquo;état des workflows dans un stockage persistant en utilisant une base de données Postgres.">
<meta name="author" content="Daniel Paes">
<link rel="canonical" href="https://pipekit.io/blog/archiving-argo-workflows-postgres-database-setup">
<meta name="google-site-verification" content="4599922566">
<link crossorigin="anonymous" href="/assets/css/stylesheet.css" rel="preload stylesheet" as="style">
<link rel="icon" href="https://www.dawrlog.com/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://www.dawrlog.com/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://www.dawrlog.com/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://www.dawrlog.com/apple-touch-icon.png">
<link rel="mask-icon" href="https://www.dawrlog.com/apple-touch-icon.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="fr" href="https://www.dawrlog.com/fr/articles/2/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="Archivage des Argo Workflows dans une instance Postgres: Quoi a faire pour configurer votre entrepôt de données" />
<meta property="og:description" content="Bonjour à tous, j&rsquo;espère que vous allez bien !
Si vous connaissez Argo Workflows, vous savez déjà qu&rsquo;il peut piloter vos pipelines CI/CD, gérer vos processus ETL et orchestrer tout ensemble de tâches que vous pouvez imaginer pour un cluster Kubernetes. Mais saviez-vous qu&rsquo;Argo sait aussi archiver les résultats de ses workflows dans une base de données SQL ?
Dans ce billet, je vais montrer comment Argo Workflows archive l&rsquo;état des workflows dans un stockage persistant en utilisant une base de données Postgres." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://www.dawrlog.com/fr/articles/2/" />
<meta property="og:image" content="https://user-images.githubusercontent.com/78096758/217074497-736145c4-11a8-4934-90ef-1d5bc3432565.png" /><meta property="article:section" content="articles" />
<meta property="article:published_time" content="2022-04-11T00:00:00+00:00" />
<meta property="article:modified_time" content="2022-04-11T00:00:00+00:00" /><meta property="og:site_name" content="Logistique Dataware" />

<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="https://user-images.githubusercontent.com/78096758/217074497-736145c4-11a8-4934-90ef-1d5bc3432565.png" />
<meta name="twitter:title" content="Archivage des Argo Workflows dans une instance Postgres: Quoi a faire pour configurer votre entrepôt de données"/>
<meta name="twitter:description" content="Bonjour à tous, j&rsquo;espère que vous allez bien !
Si vous connaissez Argo Workflows, vous savez déjà qu&rsquo;il peut piloter vos pipelines CI/CD, gérer vos processus ETL et orchestrer tout ensemble de tâches que vous pouvez imaginer pour un cluster Kubernetes. Mais saviez-vous qu&rsquo;Argo sait aussi archiver les résultats de ses workflows dans une base de données SQL ?
Dans ce billet, je vais montrer comment Argo Workflows archive l&rsquo;état des workflows dans un stockage persistant en utilisant une base de données Postgres."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Articles",
      "item": "https://www.dawrlog.com/fr/articles/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Archivage des Argo Workflows dans une instance Postgres: Quoi a faire pour configurer votre entrepôt de données",
      "item": "https://www.dawrlog.com/fr/articles/2/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Archivage des Argo Workflows dans une instance Postgres: Quoi a faire pour configurer votre entrepôt de données",
  "name": "Archivage des Argo Workflows dans une instance Postgres: Quoi a faire pour configurer votre entrepôt de données",
  "description": "Bonjour à tous, j\u0026rsquo;espère que vous allez bien !\nSi vous connaissez Argo Workflows, vous savez déjà qu\u0026rsquo;il peut piloter vos pipelines CI/CD, gérer vos processus ETL et orchestrer tout ensemble de tâches que vous pouvez imaginer pour un cluster Kubernetes. Mais saviez-vous qu\u0026rsquo;Argo sait aussi archiver les résultats de ses workflows dans une base de données SQL ?\nDans ce billet, je vais montrer comment Argo Workflows archive l\u0026rsquo;état des workflows dans un stockage persistant en utilisant une base de données Postgres.",
  "keywords": [
    "Kubernetes", "Argo", "Development", "Data Warehouse", "Best Practices"
  ],
  "articleBody": "Bonjour à tous, j’espère que vous allez bien !\nSi vous connaissez Argo Workflows, vous savez déjà qu’il peut piloter vos pipelines CI/CD, gérer vos processus ETL et orchestrer tout ensemble de tâches que vous pouvez imaginer pour un cluster Kubernetes. Mais saviez-vous qu’Argo sait aussi archiver les résultats de ses workflows dans une base de données SQL ?\nDans ce billet, je vais montrer comment Argo Workflows archive l’état des workflows dans un stockage persistant en utilisant une base de données Postgres. Pour ce faire, je présenterai un rapide résumé des composants d’Argo tout en montrant ce que signifie l’archivage de votre workflow. Nous déploierons les workflows Argo avec une base de données Postgres sur une instance locale de Kubernetes en utilisant k3d. Enfin, nous discuterons de quelques considérations de sécurité importantes pour votre déploiement d’Argo Workflows.\nAlors, c’est parti.\nQu’est-ce que l’option d’archivage dans les workflows Argo ? La possibilité de stocker les exécutions de flux de travail antérieures vous fournit un enregistrement précis de vos états de flux de travail antérieurs. Cet état des lieux change la donne, car il permet de provisionner vos ensembles de tâches en fonction de métriques en temps réel, comme les pics de besoins de traitement des déploiements passés.\nL’option d’archivage des flux de travail stocke vos états de flux de travail dans MySQL ou Postgres. Une fois les archives configurées, vous pouvez les utiliser pour mieux comprendre le fonctionnement de vos tâches et les points à améliorer.\nPar exemple, elles peuvent vous aider à savoir quand c’est une bonne idée de faire évoluer votre trafic à l’aide d’instances temporaires, dont les états seront également stockés dans la même base de données. Avec tous vos états conservés au fil du temps, vous pouvez appliquer des règles pour ajuster la taille de votre cluster en fonction de l’utilisation précédente ; une bonne analyse des séries chronologiques pourrait même vous faire économiser de l’argent au final.\nL’archive ne stocke que les états précédents du flux de travail, et non les journaux d’instance détaillés. Les journaux d’audit détaillés sont un autre élément à prendre en compte. L’option de stockage des artefacts gère l’option de persistance des journaux détaillés, en les stockant localement par MinIO. Mais vous pouvez également configurer toute autre option de stockage d’objets. Ceci est couvert dans la documentation officielle d’Argo, où vous pouvez voir comment utiliser des options telles que les buckets Google Cloud Storage ou AWS S3.\nMais avant de commencer l’implémentation technique, faisons un rapide rappel sur les composants des workflows Argo. Il est nécessaire de savoir comment ils sont corrélés avec le stockage persistant de vos workflows archivés ; cette image tirée de la documentation des workflows Argo présente une vue d’ensemble de l’environnement où réside un workflow :\n_Source : Dépôt Github du flux de travail Argo. How to Deploy Argo Workflows with Persistent Storage\nNow that we know what’s in store for us let’s get started. We’ll be using k3d to manage our local Kubernetes environment (instead of minikube and VirtualBox). In addition to k3d, you’ll need to install Docker as an additional dependency. Using kubectl to interact with your Kubernetes cluster works fine, too. As for our tutorial, we’ll be using local Kubernetes deployment scripts.\nFirst, we’ll start our local control plane with the following command:\nk3d cluster create cluster-demo The successful creation will provide a log similar to this one:\nCreating the cluster\nOnce we have our `cluster-demo`, we'll deploy our Argo Workflows instance. To install Argo Workflows, you'll need to execute the following commands: kubectl create ns argo kubectl apply -n argo -f https://raw.githubusercontent.com/argoproj/argo-workflows/master/manifests/quick-start-postgres.yaml La première crée un espace de nom appelé argo dans votre cluster, et la ligne suivante va déployer les composants des workflows Argo sur votre cluster, comme vous pouvez le voir ci-dessous :\nDéploiements effectués sur le cluster\nCréer le contrôleur de workflow Pour exécuter le workflow avec l’option d’archivage, vous devez d’abord changer la configuration de persistance à archive:true sur votre déploiement de serveur Argo. En la modifiant, vous indiquerez à votre serveur Argo de stocker les états d’exécution de votre workflow dans la base de données signalée par la clé postgresql.\nNous appliquerons un nouveau ConfigMap dans notre espace de noms Kubernetes argo actuel avec l’instance Postgres pour stocker vos workflows archivés. Vous pouvez ensuite archiver vos workflows en utilisant l’option archiveLogs.\nNous avons déployé une instance Postgres avec le YAML de démarrage rapide que nous avons utilisé précédemment. Vous en aurez besoin uniquement pour appliquer la configuration suivante à votre déploiement. Changer cette configuration permet à votre déploiement de serveur Argo d’accepter la notation archiveLocation.archiveLogs lors de la création de vos workflows. Nous allons commencer par créer un nouveau workflow-controller-configmap.yml avec le contenu suivant et le sauvegarder localement :\napiVersion : v1 kind : ConfigMap métadonnées : nom : workflow-controller-configmap données : persistance : | connectionPool : maxIdleConns : 100 maxOpenConns : 0 connMaxLifetime : 0s nodeStatusOffLoad : true archive : true archiveTTL : 7d postgresql : hôte : postgres port : 5432 base de données : postgres tableName : argo_workflows nom d'utilisateurSecret : nom : argo-postgres-config clé : username passwordSecret : nom : argo-postgres-config clé : mot de passe retentionPolicy : | terminé : 10 échoué : 3 erroné : 3 Déployer votre environnement avec kubectl Nous allons exposer l’interface web des workflows Argo en utilisant un équilibreur de charge sur notre espace de nom argo. L’équilibreur de charge exposera le pod exécutant le composant web aux connexions provenant de l’extérieur de Kubernetes.\nkubectl apply -n argo -f workflow-controller-configmap.yml Votre serveur Argo va redémarrer avec la nouvelle configuration dans quelques minutes. N’hésitez pas à vérifier son état en exécutant kubectl get -n argo svc,pod sur votre cluster Kubernetes.\nkubectl get -n argo svc,pod Vous pouvez ensuite lier votre cluster Kubernetes et votre hôte au port 2746 en exécutant la commande suivante sur votre cluster :\nkubectl -n argo port-forward deployment/argo-server 2746:2746 \u0026 Félicitations, vous venez de déployer les workflows Argo sur un cluster k3d. Pour confirmer que votre instance locale est opérationnelle, rendez-vous sur https://localhost:2746.\nPage de l’interface utilisateur des flux de travail Argo. Testing Your Deployment\nFélicitations pour avoir installé votre instance Argo Workflows sur votre cluster Kubernetes local avec l’option d’archivage. Et maintenant que nous avons coché cela sur notre liste, archivons nos workflows. L’ajout de l’annotation archiveLogs vous permet de spécifier ceux que vous souhaitez archiver, comme le montre le modèle suivant, que nous appellerons workflow-archive.yml.\napiVersion : argoproj.io/v1alpha1 kind : Flux de travail métadonnées : generateName : archive-location- spec : archiveLogs : true # active les journaux pour ce flux de travail point d'entrée : whalesay modèles : - nom : whalesay conteneur : image : docker/whalesay:latest commande : [cowsay] args : [\"hello world\"](Bonjour monde) Nous devons exécuter argo submit -n argo --watch -f workflow-archive.yml sur un terminal pour le déployer.\nargo submit -n argo --watch -f workflow-archive.yml En faisant cela, vous lancerez le workflow archive-location sous l’espace de noms argo ; la sortie suivante confirme que notre exemple s’est exécuté avec succès :\nExemple d’archivage des flux de travail Argo\nCela ne change pas sur la ligne de commande ; cependant, comme nous avons un stockage persistant pour nos workflows, vous pouvez voir leurs états précédents sur l’interface utilisateur de la console. Cela vous donnera les états précédents du workflow qui ont été exécutés avec les options d’archivage activées - et en allant sur l’interface utilisateur de la console Argo Workflows à https://localhost:2746, comme nous l’avons vu précédemment, vous pouvez accéder à l’option d’interface utilisateur du workflow archivé depuis les icônes de la barre de menu de gauche. Une fois que vous êtes là, vous pouvez voir toutes les exécutions passées d’un workflow. L’historique de votre workflow se trouve dans l’interface utilisateur sous “Workflows archivés” (voir ci-dessous).\nEcran d’archivage des flux de travail Argo Bonnes pratiques de sécurité pour l’archivage des flux de travail Argo dans Postgres.\nDans notre travail, nous avons déployé une instance Argo avec l’option d’archivage configurée avec une base de données Postgres. Comme mentionné précédemment, ce code n’est pas prêt pour la production. Comme prochaine étape, je suggère de gérer vos jetons d’accès pour sécuriser votre instance Argo.\nUne bonne pratique est d’éviter les valeurs codées en dur pour les informations d’exécution du serveur lorsque cela est possible. Votre infrastructure devrait générer des données comme votre nom d’hôte Postgres au moment de l’exécution au lieu de les coder en dur. Votre infrastructure devrait utiliser des secrets pour stocker des informations sensibles comme les clés d’accès au référentiel.\nArchivage Postgres\nJetez un œil à cette introduction sur les secrets et les configmaps dans Kubernetes, pour plus de détails sur les informations Kubernetes qui doivent être discrètes. L’adoption de bonnes pratiques de sécurité comme celle-ci dès le début est plus facile pour vos utilisateurs et vos développeurs lorsque vous commencez à évoluer. En outre, l’automatisation de la configuration permet de réduire la surface d’attaque de votre environnement tout en réduisant les tâches de gestion de l’infrastructure.\nVoici un article de blog utile contenant d’autres bonnes pratiques de sécurité Argo par le responsable des flux de travail Argo, Alex Collins.\nConclusion\nNous avons déployé Argo Workflows localement et archivé un workflow en utilisant une base de données Postgres dans ce post. Les scripts présentés ici sont de bons points de départ pour comprendre et expérimenter l’option d’archivage d’Argo Workflows, mais gardez à l’esprit que certains facteurs critiques sont manquants pour un environnement entièrement cloud native.\nA+ !\n",
  "wordCount" : "1577",
  "inLanguage": "fr",
  "image":"https://user-images.githubusercontent.com/78096758/217074497-736145c4-11a8-4934-90ef-1d5bc3432565.png","datePublished": "2022-04-11T00:00:00Z",
  "dateModified": "2022-04-11T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Daniel Paes"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://www.dawrlog.com/fr/articles/2/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Logistique Dataware",
    "logo": {
      "@type": "ImageObject",
      "url": "https://www.dawrlog.com/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://www.dawrlog.com/fr/" accesskey="h" title="Logistique Dataware (Alt + H)">Logistique Dataware</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
                <ul class="lang-switch"><li>|</li>
                    <li>
                        <a href="https://www.dawrlog.com/" title="English"
                            aria-label=":us:">🇺🇸</a>
                    </li>
                </ul>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://www.dawrlog.com/fr/apropos" title="À Propos">
                    <span>À Propos</span>
                </a>
            </li>
            <li>
                <a href="https://www.dawrlog.com/fr/articles/" title="Articles">
                    <span>Articles</span>
                </a>
            </li>
            <li>
                <a href="https://calendly.com/dawrlog" title="Contactez-nous">
                    <span>Contactez-nous</span>&nbsp;
                    <svg fill="none" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round"
                        stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12">
                        <path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"></path>
                        <path d="M15 3h6v6"></path>
                        <path d="M10 14L21 3"></path>
                    </svg>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://www.dawrlog.com/fr/">Accueil</a>&nbsp;»&nbsp;<a href="https://www.dawrlog.com/fr/articles/">Articles</a></div>
    <h1 class="post-title">
      Archivage des Argo Workflows dans une instance Postgres: Quoi a faire pour configurer votre entrepôt de données
    </h1>
    <div class="post-meta"><span title='2022-04-11 00:00:00 +0000 UTC'>avril 11, 2022</span>&nbsp;·&nbsp;8 min&nbsp;·&nbsp;Daniel Paes

</div>
  </header> 
<figure class="entry-cover"><img loading="lazy" src="https://user-images.githubusercontent.com/78096758/217074497-736145c4-11a8-4934-90ef-1d5bc3432565.png" alt="">
        
</figure><div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table des matières</span>
        </summary>

        <div class="inner"><nav id="TableOfContents">
  <ul>
    <li><a href="#h2quest-ce-que-loption-darchivage-dans-les-workflows-argo-h2-br-"><h2>Qu&rsquo;est-ce que l&rsquo;option d&rsquo;archivage dans les workflows Argo ?</h2> <br /></a></li>
    <li><a href="#h2how-to-deploy-argo-workflows-with-persistent-storageh2br-"><h2>How to Deploy Argo Workflows with Persistent Storage</h2><br /></a></li>
    <li><a href="#h2créer-le-contrôleur-de-workflow-h2br-"><h2>Créer le contrôleur de workflow </h2><br /></a></li>
    <li><a href="#h2testing-your-deploymenth2br-"><h2>Testing Your Deployment</h2><br /></a>
      <ul>
        <li><a href="#h2bonnes-pratiques-de-sécurité-pour-larchivage-des-flux-de-travail-argo-dans-postgresh2br-"><h2>Bonnes pratiques de sécurité pour l&rsquo;archivage des flux de travail Argo dans Postgres.</h2><br /></a></li>
      </ul>
    </li>
    <li><a href="#h2conclusionh2br-"><h2>Conclusion</h2><br /></a></li>
  </ul>
</nav>
        </div>
    </details>
</div>

  <div class="post-content"><p>Bonjour à tous, j&rsquo;espère que vous allez bien !</p>
<p>Si vous connaissez <a href="https://argoproj.github.io/workflows/">Argo Workflows</a>, vous savez déjà qu&rsquo;il peut piloter vos pipelines CI/CD, gérer vos processus ETL et orchestrer tout ensemble de tâches que vous pouvez imaginer pour un cluster Kubernetes. Mais saviez-vous qu&rsquo;Argo sait aussi archiver les résultats de ses workflows dans une base de données SQL ?</p>
<p>Dans ce billet, je vais montrer comment Argo Workflows archive l&rsquo;état des workflows dans un stockage persistant en utilisant une base de données Postgres. Pour ce faire, je présenterai un rapide résumé des composants d&rsquo;Argo tout en montrant ce que signifie l&rsquo;archivage de votre workflow. Nous déploierons les workflows Argo avec une base de données Postgres sur une instance locale de Kubernetes en utilisant <a href="https://k3d.io/v5.3.0/">k3d</a>. Enfin, nous discuterons de quelques considérations de sécurité importantes pour votre déploiement d&rsquo;Argo Workflows.</p>
<p>Alors, c&rsquo;est parti.</p>
<h2 id="h2quest-ce-que-loption-darchivage-dans-les-workflows-argo-h2-br-"><h2>Qu&rsquo;est-ce que l&rsquo;option d&rsquo;archivage dans les workflows Argo ?</h2> <br /><a hidden class="anchor" aria-hidden="true" href="#h2quest-ce-que-loption-darchivage-dans-les-workflows-argo-h2-br-">#</a></h2>
<p>La possibilité de stocker les exécutions de flux de travail antérieures vous fournit un enregistrement précis de vos états de flux de travail antérieurs. Cet état des lieux change la donne, car il permet de provisionner vos ensembles de tâches en fonction de métriques en temps réel, comme les pics de besoins de traitement des déploiements passés.</p>
<p>L&rsquo;option d&rsquo;archivage des flux de travail stocke vos états de flux de travail dans MySQL ou Postgres. Une fois les archives configurées, vous pouvez les utiliser pour mieux comprendre le fonctionnement de vos tâches et les points à améliorer.</p>
<p>Par exemple, elles peuvent vous aider à savoir quand c&rsquo;est une bonne idée de faire évoluer votre trafic à l&rsquo;aide d&rsquo;instances temporaires, dont les états seront également stockés dans la même base de données. Avec tous vos états conservés au fil du temps, vous pouvez appliquer des règles pour ajuster la taille de votre cluster en fonction de l&rsquo;utilisation précédente ; une bonne analyse des séries chronologiques pourrait même vous faire économiser de l&rsquo;argent au final.</p>
<p><img loading="lazy" src="https://user-images.githubusercontent.com/78096758/217069095-b10d7ff5-01f1-4213-98c4-02a35869a736.png" alt="archivage postgres"  />

<br /></p>
<p>L&rsquo;archive ne stocke que les états précédents du flux de travail, et non les journaux d&rsquo;instance détaillés. Les journaux d&rsquo;audit détaillés sont un autre élément à prendre en compte. L&rsquo;option de stockage des artefacts gère l&rsquo;option de persistance des journaux détaillés, en les stockant localement par <a href="https://min.io/">MinIO</a>. Mais vous pouvez également configurer toute autre option de stockage d&rsquo;objets. Ceci est couvert dans la <a href="https://argoproj.github.io/argo-workflows/configure-artifact-repository/">documentation officielle d&rsquo;Argo</a>, où vous pouvez voir comment utiliser des options telles que les buckets <a href="https://cloud.google.com/storage">Google Cloud Storage</a> ou <a href="https://aws.amazon.com/s3/">AWS S3</a>.</p>
<p>Mais avant de commencer l&rsquo;implémentation technique, faisons un rapide rappel sur les composants des workflows Argo. Il est nécessaire de savoir comment ils sont corrélés avec le stockage persistant de vos workflows archivés ; cette image tirée de la documentation des workflows Argo présente une vue d&rsquo;ensemble de l&rsquo;environnement où réside un workflow :</p>
<p><img loading="lazy" src="https://user-images.githubusercontent.com/78096758/217069401-e63ad934-46ae-4561-91ca-262089dd0131.png" alt="Diagramme des flux de travail Argo"  />

_Source : Dépôt Github du flux de travail Argo.
<br /></p>
<h2 id="h2how-to-deploy-argo-workflows-with-persistent-storageh2br-"><h2>How to Deploy Argo Workflows with Persistent Storage</h2><br /><a hidden class="anchor" aria-hidden="true" href="#h2how-to-deploy-argo-workflows-with-persistent-storageh2br-">#</a></h2>
<p>Now that we know what&rsquo;s in store for us let&rsquo;s get started. We&rsquo;ll be using k3d to manage our local Kubernetes environment (instead of minikube and VirtualBox). In addition to k3d, you&rsquo;ll need to install Docker as an additional dependency. Using kubectl to interact with your Kubernetes cluster works fine, too. As for our tutorial, we&rsquo;ll be using local Kubernetes deployment scripts.</p>
<p>First, we&rsquo;ll start our local control plane with the following command:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">k3d cluster create cluster-demo 
</span></span></code></pre></div><p>The successful creation will provide a log similar to this one:</p>
<p><img loading="lazy" src="https://user-images.githubusercontent.com/78096758/217070632-b181c8a9-f684-4cf5-a58a-9b50d79d18a6.png" alt="Archive Info"  />

<em>Creating the cluster</em></p>
<br/>
Once we have our `cluster-demo`, we'll deploy our Argo Workflows instance. To install Argo Workflows, you'll need to execute the following commands:
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">kubectl create ns argo
</span></span><span class="line"><span class="cl">kubectl apply -n argo -f https://raw.githubusercontent.com/argoproj/argo-workflows/master/manifests/quick-start-postgres.yaml 
</span></span></code></pre></div><p>La première crée un espace de nom appelé argo dans votre cluster, et la ligne suivante va déployer les composants des workflows Argo sur votre cluster, comme vous pouvez le voir ci-dessous :</p>
<p><img loading="lazy" src="https://user-images.githubusercontent.com/78096758/217072204-32b27544-798d-489a-8e67-02994c386620.png" alt="archivage postgres"  />

<em>Déploiements effectués sur le cluster</em></p>
<h2 id="h2créer-le-contrôleur-de-workflow-h2br-"><h2>Créer le contrôleur de workflow </h2><br /><a hidden class="anchor" aria-hidden="true" href="#h2créer-le-contrôleur-de-workflow-h2br-">#</a></h2>
<p>Pour exécuter le workflow avec l&rsquo;option d&rsquo;archivage, vous devez d&rsquo;abord changer la configuration de persistance à <code>archive:true</code> sur votre déploiement de serveur Argo. En la modifiant, vous indiquerez à votre serveur Argo de stocker les états d&rsquo;exécution de votre workflow dans la base de données signalée par la clé <code>postgresql</code>.</p>
<p>Nous appliquerons un nouveau <code>ConfigMap</code> dans notre espace de noms Kubernetes argo actuel avec l&rsquo;instance Postgres pour stocker vos workflows archivés. Vous pouvez ensuite archiver vos workflows en utilisant l&rsquo;option <code>archiveLogs</code>.</p>
<p>Nous avons déployé une instance Postgres avec le YAML de démarrage rapide que nous avons utilisé précédemment. Vous en aurez besoin uniquement pour appliquer la configuration suivante à votre déploiement. Changer cette configuration permet à votre déploiement de serveur Argo d&rsquo;accepter la notation <code>archiveLocation.archiveLogs</code> lors de la création de vos workflows. Nous allons commencer par créer un nouveau <code>workflow-controller-configmap.yml</code> avec le contenu suivant et le sauvegarder localement :</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">apiVersion : v1
</span></span><span class="line"><span class="cl">kind : ConfigMap
</span></span><span class="line"><span class="cl">métadonnées :
</span></span><span class="line"><span class="cl">  nom : workflow-controller-configmap
</span></span><span class="line"><span class="cl">données :
</span></span><span class="line"><span class="cl">  persistance : <span class="p">|</span>
</span></span><span class="line"><span class="cl">    connectionPool :
</span></span><span class="line"><span class="cl">      maxIdleConns : <span class="m">100</span>
</span></span><span class="line"><span class="cl">      maxOpenConns : <span class="m">0</span>
</span></span><span class="line"><span class="cl">      connMaxLifetime : 0s
</span></span><span class="line"><span class="cl">    nodeStatusOffLoad : <span class="nb">true</span>
</span></span><span class="line"><span class="cl">    archive : <span class="nb">true</span>
</span></span><span class="line"><span class="cl">    archiveTTL : 7d
</span></span><span class="line"><span class="cl">    postgresql :
</span></span><span class="line"><span class="cl">      hôte : postgres
</span></span><span class="line"><span class="cl">      port : <span class="m">5432</span>
</span></span><span class="line"><span class="cl">      base de données : postgres
</span></span><span class="line"><span class="cl">      tableName : argo_workflows
</span></span><span class="line"><span class="cl">      nom d<span class="err">&#39;</span>utilisateurSecret :
</span></span><span class="line"><span class="cl">        nom : argo-postgres-config
</span></span><span class="line"><span class="cl">        clé : username
</span></span><span class="line"><span class="cl">      passwordSecret :
</span></span><span class="line"><span class="cl">        nom : argo-postgres-config
</span></span><span class="line"><span class="cl">        clé : mot de passe
</span></span><span class="line"><span class="cl">  retentionPolicy : <span class="p">|</span>
</span></span><span class="line"><span class="cl">    terminé : <span class="m">10</span>
</span></span><span class="line"><span class="cl">    échoué : <span class="m">3</span>
</span></span><span class="line"><span class="cl">    erroné : <span class="m">3</span> 
</span></span></code></pre></div><p>Déployer votre environnement avec kubectl
Nous allons exposer l&rsquo;interface web des workflows Argo en utilisant un équilibreur de charge sur notre espace de nom argo. L&rsquo;équilibreur de charge exposera le pod exécutant le composant web aux connexions provenant de l&rsquo;extérieur de Kubernetes.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">kubectl apply -n argo -f workflow-controller-configmap.yml 
</span></span></code></pre></div><p>Votre serveur Argo va redémarrer avec la nouvelle configuration dans quelques minutes. N&rsquo;hésitez pas à vérifier son état en exécutant <code>kubectl get -n argo svc,pod</code> sur votre cluster Kubernetes.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">kubectl get -n argo svc,pod 
</span></span></code></pre></div><p>Vous pouvez ensuite lier votre cluster Kubernetes et votre hôte au port 2746 en exécutant la commande suivante sur votre cluster :</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">kubectl -n argo port-forward deployment/argo-server 2746:2746 <span class="p">&amp;</span> 
</span></span></code></pre></div><p>Félicitations, vous venez de déployer les workflows Argo sur un cluster k3d. Pour confirmer que votre instance locale est opérationnelle, rendez-vous sur <code>https://localhost:2746</code>.</p>
<p><img loading="lazy" src="https://user-images.githubusercontent.com/78096758/217072659-01210f43-c734-49d3-8282-0dfbc8b5c49f.png" alt="Argo Workflow User info UI"  />

Page de l&rsquo;interface utilisateur des flux de travail Argo.
<br /></p>
<h2 id="h2testing-your-deploymenth2br-"><h2>Testing Your Deployment</h2><br /><a hidden class="anchor" aria-hidden="true" href="#h2testing-your-deploymenth2br-">#</a></h2>
<p>Félicitations pour avoir installé votre instance Argo Workflows sur votre cluster Kubernetes local avec l&rsquo;option d&rsquo;archivage. Et maintenant que nous avons coché cela sur notre liste, archivons nos workflows. L&rsquo;ajout de l&rsquo;annotation <code>archiveLogs</code> vous permet de spécifier ceux que vous souhaitez archiver, comme le montre le modèle suivant, que nous appellerons <code>workflow-archive.yml</code>.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">apiVersion : argoproj.io/v1alpha1
</span></span><span class="line"><span class="cl">kind : Flux de travail
</span></span><span class="line"><span class="cl">métadonnées :
</span></span><span class="line"><span class="cl">  generateName : archive-location-
</span></span><span class="line"><span class="cl">spec :
</span></span><span class="line"><span class="cl">  archiveLogs : <span class="nb">true</span> <span class="c1"># active les journaux pour ce flux de travail</span>
</span></span><span class="line"><span class="cl">  point d<span class="err">&#39;</span>entrée : whalesay
</span></span><span class="line"><span class="cl">  modèles :
</span></span><span class="line"><span class="cl">  - nom : whalesay
</span></span><span class="line"><span class="cl">    conteneur :
</span></span><span class="line"><span class="cl">      image : docker/whalesay:latest
</span></span><span class="line"><span class="cl">      commande : <span class="o">[</span>cowsay<span class="o">]</span>
</span></span><span class="line"><span class="cl">      args : <span class="o">[</span><span class="s2">&#34;hello world&#34;</span><span class="o">](</span>Bonjour monde<span class="o">)</span> 
</span></span></code></pre></div><p>Nous devons exécuter <code>argo submit -n argo --watch -f workflow-archive.yml</code> sur un terminal pour le déployer.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">argo submit -n argo --watch -f workflow-archive.yml 
</span></span></code></pre></div><p>En faisant cela, vous lancerez le workflow <code>archive-location</code> sous l&rsquo;espace de noms <code>argo</code> ; la sortie suivante confirme que notre exemple s&rsquo;est exécuté avec succès :</p>
<p><img loading="lazy" src="https://user-images.githubusercontent.com/78096758/217072867-ae971ca3-0776-462a-8b8b-1209498873d6.png" alt="Argo Workflow Archive example"  />

<em>Exemple d&rsquo;archivage des flux de travail Argo</em><br /></p>
<p>Cela ne change pas sur la ligne de commande ; cependant, comme nous avons un stockage persistant pour nos workflows, vous pouvez voir leurs états précédents sur l&rsquo;interface utilisateur de la console. Cela vous donnera les états précédents du workflow qui ont été exécutés avec les options d&rsquo;archivage activées - et en allant sur l&rsquo;interface utilisateur de la console Argo Workflows à <code>https://localhost:2746</code>, comme nous l&rsquo;avons vu précédemment, vous pouvez accéder à l&rsquo;option d&rsquo;interface utilisateur du workflow archivé depuis les icônes de la barre de menu de gauche. Une fois que vous êtes là, vous pouvez voir toutes les exécutions passées d&rsquo;un workflow. L&rsquo;historique de votre workflow se trouve dans l&rsquo;interface utilisateur sous &ldquo;Workflows archivés&rdquo; (voir ci-dessous).</p>
<p><img loading="lazy" src="https://user-images.githubusercontent.com/78096758/217073174-b3762346-615e-4b90-8752-b2521acf769d.png" alt="Console des workflows archivés d&amp;rsquo;Argo"  />

<em>Ecran d&rsquo;archivage des flux de travail Argo</em>
<br />
<br /></p>
<h3 id="h2bonnes-pratiques-de-sécurité-pour-larchivage-des-flux-de-travail-argo-dans-postgresh2br-"><h2>Bonnes pratiques de sécurité pour l&rsquo;archivage des flux de travail Argo dans Postgres.</h2><br /><a hidden class="anchor" aria-hidden="true" href="#h2bonnes-pratiques-de-sécurité-pour-larchivage-des-flux-de-travail-argo-dans-postgresh2br-">#</a></h3>
<p>Dans notre travail, nous avons déployé une instance Argo avec l&rsquo;option d&rsquo;archivage configurée avec une base de données Postgres. Comme mentionné précédemment, ce code n&rsquo;est pas prêt pour la production. Comme prochaine étape, je suggère de gérer vos jetons d&rsquo;accès pour sécuriser votre instance Argo.</p>
<p>Une bonne pratique est d&rsquo;éviter les valeurs codées en dur pour les informations d&rsquo;exécution du serveur lorsque cela est possible. Votre infrastructure devrait générer des données comme votre nom d&rsquo;hôte Postgres au moment de l&rsquo;exécution au lieu de les coder en dur. Votre infrastructure devrait utiliser des secrets pour stocker des informations sensibles comme les clés d&rsquo;accès au référentiel.</p>
<p><img loading="lazy" src="https://user-images.githubusercontent.com/78096758/217073499-91ffe20f-6625-42ff-9688-b1b436fa6f1f.png" alt="Archivage Postgres"  />

<em>Archivage Postgres</em></p>
<p>Jetez un œil à cette <a href="https://opensource.com/article/19/6/introduction-kubernetes-secrets-and-configmaps">introduction sur les secrets et les configmaps dans Kubernetes</a>, pour plus de détails sur les informations Kubernetes qui doivent être discrètes. L&rsquo;adoption de bonnes pratiques de sécurité comme celle-ci dès le début est plus facile pour vos utilisateurs et vos développeurs lorsque vous commencez à évoluer. En outre, l&rsquo;automatisation de la configuration permet de réduire la <a href="https://csrc.nist.gov/glossary/term/attack_surface">surface d&rsquo;attaque</a> de votre environnement tout en réduisant les tâches de gestion de l&rsquo;infrastructure.</p>
<p>Voici un <a href="https://blog.argoproj.io/practical-argo-workflows-hardening-dd8429acc1ce">article de blog utile</a> contenant d&rsquo;autres bonnes pratiques de sécurité Argo par le responsable des flux de travail Argo, Alex Collins.</p>
<h2 id="h2conclusionh2br-"><h2>Conclusion</h2><br /><a hidden class="anchor" aria-hidden="true" href="#h2conclusionh2br-">#</a></h2>
<p>Nous avons déployé Argo Workflows localement et archivé un workflow en utilisant une base de données Postgres dans ce post. Les scripts présentés ici sont de bons points de départ pour comprendre et expérimenter l&rsquo;option d&rsquo;archivage d&rsquo;Argo Workflows, mais gardez à l&rsquo;esprit que certains facteurs critiques sont manquants pour un environnement entièrement cloud native.</p>
<p>A+ !</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
<nav class="paginav">
  <a class="prev" href="https://www.dawrlog.com/fr/articles/4/">
    <span class="title">« Page précédente</span>
    <br>
    <span>Moyens de debug un workflow Argo.</span>
  </a>
  <a class="next" href="https://www.dawrlog.com/fr/articles/3/">
    <span class="title">Page suivante »</span>
    <br>
    <span>Comment diminuer les attaques DDOS parmis vos APIs.</span>
  </a>
</nav>


<div class="share-buttons">
    <a target="_blank" rel="noopener noreferrer" aria-label="share Archivage des Argo Workflows dans une instance Postgres: Quoi a faire pour configurer votre entrepôt de données on twitter"
        href="https://twitter.com/intent/tweet/?text=Archivage%20des%20Argo%20Workflows%20dans%20une%20instance%20Postgres%3a%20Quoi%20a%20faire%20pour%20configurer%20votre%20entrep%c3%b4t%20de%20donn%c3%a9es&amp;url=https%3a%2f%2fwww.dawrlog.com%2ffr%2farticles%2f2%2f&amp;hashtags=Kubernetes%2cArgo%2cDevelopment%2cDataWarehouse%2cBestPractices">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-253.927,424.544c135.939,0 210.268,-112.643 210.268,-210.268c0,-3.218 0,-6.437 -0.153,-9.502c14.406,-10.421 26.973,-23.448 36.935,-38.314c-13.18,5.824 -27.433,9.809 -42.452,11.648c15.326,-9.196 26.973,-23.602 32.49,-40.92c-14.252,8.429 -30.038,14.56 -46.896,17.931c-13.487,-14.406 -32.644,-23.295 -53.946,-23.295c-40.767,0 -73.87,33.104 -73.87,73.87c0,5.824 0.613,11.494 1.992,16.858c-61.456,-3.065 -115.862,-32.49 -152.337,-77.241c-6.284,10.881 -9.962,23.601 -9.962,37.088c0,25.594 13.027,48.276 32.95,61.456c-12.107,-0.307 -23.448,-3.678 -33.41,-9.196l0,0.92c0,35.862 25.441,65.594 59.311,72.49c-6.13,1.686 -12.72,2.606 -19.464,2.606c-4.751,0 -9.348,-0.46 -13.946,-1.38c9.349,29.426 36.628,50.728 68.965,51.341c-25.287,19.771 -57.164,31.571 -91.8,31.571c-5.977,0 -11.801,-0.306 -17.625,-1.073c32.337,21.15 71.264,33.41 112.95,33.41Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Archivage des Argo Workflows dans une instance Postgres: Quoi a faire pour configurer votre entrepôt de données on linkedin"
        href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fwww.dawrlog.com%2ffr%2farticles%2f2%2f&amp;title=Archivage%20des%20Argo%20Workflows%20dans%20une%20instance%20Postgres%3a%20Quoi%20a%20faire%20pour%20configurer%20votre%20entrep%c3%b4t%20de%20donn%c3%a9es&amp;summary=Archivage%20des%20Argo%20Workflows%20dans%20une%20instance%20Postgres%3a%20Quoi%20a%20faire%20pour%20configurer%20votre%20entrep%c3%b4t%20de%20donn%c3%a9es&amp;source=https%3a%2f%2fwww.dawrlog.com%2ffr%2farticles%2f2%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Archivage des Argo Workflows dans une instance Postgres: Quoi a faire pour configurer votre entrepôt de données on reddit"
        href="https://reddit.com/submit?url=https%3a%2f%2fwww.dawrlog.com%2ffr%2farticles%2f2%2f&title=Archivage%20des%20Argo%20Workflows%20dans%20une%20instance%20Postgres%3a%20Quoi%20a%20faire%20pour%20configurer%20votre%20entrep%c3%b4t%20de%20donn%c3%a9es">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Archivage des Argo Workflows dans une instance Postgres: Quoi a faire pour configurer votre entrepôt de données on facebook"
        href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fwww.dawrlog.com%2ffr%2farticles%2f2%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Archivage des Argo Workflows dans une instance Postgres: Quoi a faire pour configurer votre entrepôt de données on whatsapp"
        href="https://api.whatsapp.com/send?text=Archivage%20des%20Argo%20Workflows%20dans%20une%20instance%20Postgres%3a%20Quoi%20a%20faire%20pour%20configurer%20votre%20entrep%c3%b4t%20de%20donn%c3%a9es%20-%20https%3a%2f%2fwww.dawrlog.com%2ffr%2farticles%2f2%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Archivage des Argo Workflows dans une instance Postgres: Quoi a faire pour configurer votre entrepôt de données on telegram"
        href="https://telegram.me/share/url?text=Archivage%20des%20Argo%20Workflows%20dans%20une%20instance%20Postgres%3a%20Quoi%20a%20faire%20pour%20configurer%20votre%20entrep%c3%b4t%20de%20donn%c3%a9es&amp;url=https%3a%2f%2fwww.dawrlog.com%2ffr%2farticles%2f2%2f">
        <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
            <path
                d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
        </svg>
    </a>
</div>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2023 <a href="https://www.dawrlog.com/fr/">Logistique Dataware</a>; <br /> created with 🧡 on 🐧 machines running ☸️ pods.</span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a><script src='https://storage.ko-fi.com/cdn/scripts/overlay-widget.js'></script>
<script>
  kofiWidgetOverlay.draw('dawrlog', {
    'type': 'floating-chat',
    'floating-chat.donateButton.text': 'Tip jar',
    'floating-chat.donateButton.background-color': '#794bc4',
    'floating-chat.donateButton.text-color': '#fff'
  });
</script>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'Copier';

        function copyingDone() {
            copybutton.innerHTML = 'Copié !';
            setTimeout(() => {
                copybutton.innerHTML = 'Copier';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
